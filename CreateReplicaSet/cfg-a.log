2019-09-25T16:02:15.933+0530 I CONTROL  [initandlisten] MongoDB starting : pid=8646 port=57040 dbpath=/data/config/config-a 64-bit host=ShailendraMishra-anmepls-MacBook-Pro.local
2019-09-25T16:02:15.933+0530 I CONTROL  [initandlisten] db version v4.0.3
2019-09-25T16:02:15.934+0530 I CONTROL  [initandlisten] git version: 7ea530946fa7880364d88c8d8b6026bbc9ffa48c
2019-09-25T16:02:15.934+0530 I CONTROL  [initandlisten] allocator: system
2019-09-25T16:02:15.934+0530 I CONTROL  [initandlisten] modules: none
2019-09-25T16:02:15.934+0530 I CONTROL  [initandlisten] build environment:
2019-09-25T16:02:15.935+0530 I CONTROL  [initandlisten]     distarch: x86_64
2019-09-25T16:02:15.935+0530 I CONTROL  [initandlisten]     target_arch: x86_64
2019-09-25T16:02:15.935+0530 I CONTROL  [initandlisten] options: { net: { port: 57040 }, processManagement: { fork: true }, replication: { replSet: "conf" }, sharding: { clusterRole: "configsvr" }, storage: { dbPath: "/data/config/config-a", mmapv1: { smallFiles: true } }, systemLog: { destination: "file", path: "cfg-a.log" } }
2019-09-25T16:02:15.936+0530 I STORAGE  [initandlisten] wiredtiger_open config: create,cache_size=3584M,session_max=20000,eviction=(threads_min=4,threads_max=4),config_base=false,statistics=(fast),log=(enabled=true,archive=true,path=journal,compressor=snappy),file_manager=(close_idle_time=100000),statistics_log=(wait=0),verbose=(recovery_progress),
2019-09-25T16:02:16.459+0530 I STORAGE  [initandlisten] WiredTiger message [1569407536:459680][8646:0x1131455c0], txn-recover: Set global recovery timestamp: 0
2019-09-25T16:02:16.517+0530 I RECOVERY [initandlisten] WiredTiger recoveryTimestamp. Ts: Timestamp(0, 0)
2019-09-25T16:02:16.600+0530 W STORAGE  [initandlisten] Detected configuration for non-active storage engine mmapv1 when current storage engine is wiredTiger
2019-09-25T16:02:16.601+0530 I CONTROL  [initandlisten] 
2019-09-25T16:02:16.601+0530 I CONTROL  [initandlisten] ** WARNING: Access control is not enabled for the database.
2019-09-25T16:02:16.602+0530 I CONTROL  [initandlisten] **          Read and write access to data and configuration is unrestricted.
2019-09-25T16:02:16.603+0530 I CONTROL  [initandlisten] ** WARNING: You are running this process as the root user, which is not recommended.
2019-09-25T16:02:16.604+0530 I CONTROL  [initandlisten] 
2019-09-25T16:02:16.605+0530 I CONTROL  [initandlisten] ** WARNING: This server is bound to localhost.
2019-09-25T16:02:16.606+0530 I CONTROL  [initandlisten] **          Remote systems will be unable to connect to this server. 
2019-09-25T16:02:16.606+0530 I CONTROL  [initandlisten] **          Start the server with --bind_ip <address> to specify which IP 
2019-09-25T16:02:16.607+0530 I CONTROL  [initandlisten] **          addresses it should serve responses from, or with --bind_ip_all to
2019-09-25T16:02:16.607+0530 I CONTROL  [initandlisten] **          bind to all interfaces. If this behavior is desired, start the
2019-09-25T16:02:16.608+0530 I CONTROL  [initandlisten] **          server with --bind_ip 127.0.0.1 to disable this warning.
2019-09-25T16:02:16.608+0530 I CONTROL  [initandlisten] 
2019-09-25T16:02:16.609+0530 I CONTROL  [initandlisten] 
2019-09-25T16:02:16.609+0530 I CONTROL  [initandlisten] ** WARNING: soft rlimits too low. Number of files is 256, should be at least 1000
2019-09-25T16:02:16.614+0530 I STORAGE  [initandlisten] createCollection: local.startup_log with generated UUID: 26b40962-ff3c-4e4b-8f86-dabb91d5d6a2
2019-09-25T16:02:16.709+0530 I FTDC     [initandlisten] Initializing full-time diagnostic data capture with directory '/data/config/config-a/diagnostic.data'
2019-09-25T16:02:16.717+0530 I SHARDING [thread1] creating distributed lock ping thread for process ConfigServer (sleeping for 30000ms)
2019-09-25T16:02:16.718+0530 I STORAGE  [initandlisten] createCollection: local.replset.oplogTruncateAfterPoint with generated UUID: ba077ac7-eec2-4fa0-9650-b7012b45abcf
2019-09-25T16:02:16.719+0530 I SHARDING [shard registry reload] Periodic reload of shard registry failed  :: caused by :: ReadConcernMajorityNotAvailableYet: could not get updated shard list from config server :: caused by :: Read concern majority reads are currently not possible.; will retry after 30s
2019-09-25T16:02:16.797+0530 I STORAGE  [initandlisten] createCollection: local.replset.minvalid with generated UUID: d8d055bb-a26c-4c6d-bd98-59ec0e7ce3c2
2019-09-25T16:02:16.892+0530 I REPL     [initandlisten] Did not find local voted for document at startup.
2019-09-25T16:02:16.893+0530 I REPL     [initandlisten] Did not find local Rollback ID document at startup. Creating one.
2019-09-25T16:02:16.893+0530 I STORAGE  [initandlisten] createCollection: local.system.rollback.id with generated UUID: 77c992c7-863b-4fdd-bc6d-d314dcb0a099
2019-09-25T16:02:16.973+0530 I REPL     [initandlisten] Initialized the rollback ID to 1
2019-09-25T16:02:16.973+0530 I REPL     [initandlisten] Did not find local replica set configuration document at startup;  NoMatchingDocument: Did not find replica set configuration document in local.system.replset
2019-09-25T16:02:16.974+0530 I NETWORK  [initandlisten] waiting for connections on port 57040
2019-09-25T16:02:16.975+0530 I SH_REFR  [ConfigServerCatalogCacheLoader-0] Refresh for database config took 0 ms and found { _id: "config", primary: "config", partitioned: true }
2019-09-25T16:02:16.976+0530 I CONTROL  [LogicalSessionCacheRefresh] Failed to create config.system.sessions: Cannot create config.system.sessions until there are shards, will try again at the next refresh interval
2019-09-25T16:02:16.976+0530 I CONTROL  [LogicalSessionCacheRefresh] Sessions collection is not set up; waiting until next sessions refresh interval: Cannot create config.system.sessions until there are shards
2019-09-25T16:02:46.724+0530 I SHARDING [shard registry reload] Periodic reload of shard registry failed  :: caused by :: NotYetInitialized: could not get updated shard list from config server :: caused by :: Cannot use non-local read concern until replica set is finished initializing.; will retry after 30s
2019-09-25T16:03:16.728+0530 I SHARDING [shard registry reload] Periodic reload of shard registry failed  :: caused by :: NotYetInitialized: could not get updated shard list from config server :: caused by :: Cannot use non-local read concern until replica set is finished initializing.; will retry after 30s
2019-09-25T16:03:46.733+0530 I SHARDING [shard registry reload] Periodic reload of shard registry failed  :: caused by :: NotYetInitialized: could not get updated shard list from config server :: caused by :: Cannot use non-local read concern until replica set is finished initializing.; will retry after 30s
2019-09-25T16:04:16.755+0530 I SHARDING [shard registry reload] Periodic reload of shard registry failed  :: caused by :: NotYetInitialized: could not get updated shard list from config server :: caused by :: Cannot use non-local read concern until replica set is finished initializing.; will retry after 30s
2019-09-25T16:04:46.765+0530 I SHARDING [shard registry reload] Periodic reload of shard registry failed  :: caused by :: NotYetInitialized: could not get updated shard list from config server :: caused by :: Cannot use non-local read concern until replica set is finished initializing.; will retry after 30s
2019-09-25T16:05:16.771+0530 I SHARDING [shard registry reload] Periodic reload of shard registry failed  :: caused by :: NotYetInitialized: could not get updated shard list from config server :: caused by :: Cannot use non-local read concern until replica set is finished initializing.; will retry after 30s
2019-09-25T16:05:46.780+0530 I SHARDING [shard registry reload] Periodic reload of shard registry failed  :: caused by :: NotYetInitialized: could not get updated shard list from config server :: caused by :: Cannot use non-local read concern until replica set is finished initializing.; will retry after 30s
2019-09-25T16:21:10.869+0530 W SHARDING [replSetDistLockPinger] Lock pinger for proc: ConfigServer was inactive for 924118ms ms
2019-09-25T16:21:10.912+0530 I SHARDING [shard registry reload] Periodic reload of shard registry failed  :: caused by :: NotYetInitialized: could not get updated shard list from config server :: caused by :: Cannot use non-local read concern until replica set is finished initializing.; will retry after 30s
2019-09-25T16:21:40.929+0530 I SHARDING [shard registry reload] Periodic reload of shard registry failed  :: caused by :: NotYetInitialized: could not get updated shard list from config server :: caused by :: Cannot use non-local read concern until replica set is finished initializing.; will retry after 30s
2019-09-25T16:26:18.790+0530 I SHARDING [shard registry reload] Periodic reload of shard registry failed  :: caused by :: NotYetInitialized: could not get updated shard list from config server :: caused by :: Cannot use non-local read concern until replica set is finished initializing.; will retry after 30s
2019-09-25T16:26:18.946+0530 I CONTROL  [LogicalSessionCacheRefresh] Failed to create config.system.sessions: Cannot create config.system.sessions until there are shards, will try again at the next refresh interval
2019-09-25T16:26:18.947+0530 I CONTROL  [LogicalSessionCacheRefresh] Sessions collection is not set up; waiting until next sessions refresh interval: Cannot create config.system.sessions until there are shards
2019-09-25T16:26:48.796+0530 I SHARDING [shard registry reload] Periodic reload of shard registry failed  :: caused by :: NotYetInitialized: could not get updated shard list from config server :: caused by :: Cannot use non-local read concern until replica set is finished initializing.; will retry after 30s
2019-09-25T16:27:18.800+0530 I SHARDING [shard registry reload] Periodic reload of shard registry failed  :: caused by :: NotYetInitialized: could not get updated shard list from config server :: caused by :: Cannot use non-local read concern until replica set is finished initializing.; will retry after 30s
2019-09-25T16:27:48.809+0530 I SHARDING [shard registry reload] Periodic reload of shard registry failed  :: caused by :: NotYetInitialized: could not get updated shard list from config server :: caused by :: Cannot use non-local read concern until replica set is finished initializing.; will retry after 30s
2019-09-25T16:28:18.813+0530 I SHARDING [shard registry reload] Periodic reload of shard registry failed  :: caused by :: NotYetInitialized: could not get updated shard list from config server :: caused by :: Cannot use non-local read concern until replica set is finished initializing.; will retry after 30s
2019-09-25T16:28:48.820+0530 I SHARDING [shard registry reload] Periodic reload of shard registry failed  :: caused by :: NotYetInitialized: could not get updated shard list from config server :: caused by :: Cannot use non-local read concern until replica set is finished initializing.; will retry after 30s
2019-09-25T16:29:18.822+0530 I SHARDING [shard registry reload] Periodic reload of shard registry failed  :: caused by :: NotYetInitialized: could not get updated shard list from config server :: caused by :: Cannot use non-local read concern until replica set is finished initializing.; will retry after 30s
2019-09-25T16:29:48.829+0530 I SHARDING [shard registry reload] Periodic reload of shard registry failed  :: caused by :: NotYetInitialized: could not get updated shard list from config server :: caused by :: Cannot use non-local read concern until replica set is finished initializing.; will retry after 30s
2019-09-25T16:30:18.835+0530 I SHARDING [shard registry reload] Periodic reload of shard registry failed  :: caused by :: NotYetInitialized: could not get updated shard list from config server :: caused by :: Cannot use non-local read concern until replica set is finished initializing.; will retry after 30s
2019-09-25T16:30:24.850+0530 I NETWORK  [listener] connection accepted from 127.0.0.1:50297 #1 (1 connection now open)
2019-09-25T16:30:24.851+0530 I NETWORK  [conn1] received client metadata from 127.0.0.1:50297 conn1: { application: { name: "MongoDB Shell" }, driver: { name: "MongoDB Internal Client", version: "4.0.3" }, os: { type: "Darwin", name: "Mac OS X", architecture: "x86_64", version: "18.7.0" } }
2019-09-25T16:30:48.847+0530 I SHARDING [shard registry reload] Periodic reload of shard registry failed  :: caused by :: NotYetInitialized: could not get updated shard list from config server :: caused by :: Cannot use non-local read concern until replica set is finished initializing.; will retry after 30s
2019-09-25T16:31:18.852+0530 I SHARDING [shard registry reload] Periodic reload of shard registry failed  :: caused by :: NotYetInitialized: could not get updated shard list from config server :: caused by :: Cannot use non-local read concern until replica set is finished initializing.; will retry after 30s
2019-09-25T16:31:18.951+0530 I CONTROL  [LogicalSessionCacheRefresh] Failed to create config.system.sessions: Cannot create config.system.sessions until there are shards, will try again at the next refresh interval
2019-09-25T16:31:18.954+0530 I CONTROL  [LogicalSessionCacheRefresh] Sessions collection is not set up; waiting until next sessions refresh interval: Cannot create config.system.sessions until there are shards
2019-09-25T16:31:48.866+0530 I SHARDING [shard registry reload] Periodic reload of shard registry failed  :: caused by :: NotYetInitialized: could not get updated shard list from config server :: caused by :: Cannot use non-local read concern until replica set is finished initializing.; will retry after 30s
2019-09-25T16:32:18.867+0530 I SHARDING [shard registry reload] Periodic reload of shard registry failed  :: caused by :: NotYetInitialized: could not get updated shard list from config server :: caused by :: Cannot use non-local read concern until replica set is finished initializing.; will retry after 30s
2019-09-25T16:32:48.888+0530 I SHARDING [shard registry reload] Periodic reload of shard registry failed  :: caused by :: NotYetInitialized: could not get updated shard list from config server :: caused by :: Cannot use non-local read concern until replica set is finished initializing.; will retry after 30s
2019-09-25T16:33:18.898+0530 I SHARDING [shard registry reload] Periodic reload of shard registry failed  :: caused by :: NotYetInitialized: could not get updated shard list from config server :: caused by :: Cannot use non-local read concern until replica set is finished initializing.; will retry after 30s
2019-09-25T16:33:48.904+0530 I SHARDING [shard registry reload] Periodic reload of shard registry failed  :: caused by :: NotYetInitialized: could not get updated shard list from config server :: caused by :: Cannot use non-local read concern until replica set is finished initializing.; will retry after 30s
2019-09-25T16:34:18.913+0530 I SHARDING [shard registry reload] Periodic reload of shard registry failed  :: caused by :: NotYetInitialized: could not get updated shard list from config server :: caused by :: Cannot use non-local read concern until replica set is finished initializing.; will retry after 30s
2019-09-25T16:34:48.919+0530 I SHARDING [shard registry reload] Periodic reload of shard registry failed  :: caused by :: NotYetInitialized: could not get updated shard list from config server :: caused by :: Cannot use non-local read concern until replica set is finished initializing.; will retry after 30s
2019-09-25T16:35:18.922+0530 I SHARDING [shard registry reload] Periodic reload of shard registry failed  :: caused by :: NotYetInitialized: could not get updated shard list from config server :: caused by :: Cannot use non-local read concern until replica set is finished initializing.; will retry after 30s
2019-09-25T16:35:48.866+0530 I REPL     [conn1] replSetInitiate admin command received from client
2019-09-25T16:35:48.867+0530 E REPL     [conn1] Attempting to initiate a replica set with name cs, but command line reports conf; rejecting
2019-09-25T16:35:48.941+0530 I SHARDING [shard registry reload] Periodic reload of shard registry failed  :: caused by :: NotYetInitialized: could not get updated shard list from config server :: caused by :: Cannot use non-local read concern until replica set is finished initializing.; will retry after 30s
2019-09-25T16:36:18.941+0530 I SHARDING [shard registry reload] Periodic reload of shard registry failed  :: caused by :: NotYetInitialized: could not get updated shard list from config server :: caused by :: Cannot use non-local read concern until replica set is finished initializing.; will retry after 30s
2019-09-25T16:36:18.957+0530 I CONTROL  [LogicalSessionCacheRefresh] Failed to create config.system.sessions: Cannot create config.system.sessions until there are shards, will try again at the next refresh interval
2019-09-25T16:36:18.958+0530 I CONTROL  [LogicalSessionCacheRefresh] Sessions collection is not set up; waiting until next sessions refresh interval: Cannot create config.system.sessions until there are shards
2019-09-25T16:36:28.984+0530 I REPL     [conn1] replSetInitiate admin command received from client
2019-09-25T16:36:28.988+0530 I REPL     [conn1] replSetInitiate config object with 3 members parses ok
2019-09-25T16:36:28.989+0530 I ASIO     [Replication] Connecting to localhost:57041
2019-09-25T16:36:28.989+0530 I ASIO     [Replication] Connecting to localhost:57042
2019-09-25T16:36:28.992+0530 I REPL     [conn1] ******
2019-09-25T16:36:28.993+0530 I REPL     [conn1] creating replication oplog of size: 192MB...
2019-09-25T16:36:28.993+0530 I STORAGE  [conn1] createCollection: local.oplog.rs with generated UUID: daa88160-f4ee-4946-aec0-4e83f1ef2673
2019-09-25T16:36:28.994+0530 I NETWORK  [listener] connection accepted from 127.0.0.1:51786 #6 (2 connections now open)
2019-09-25T16:36:28.994+0530 I NETWORK  [listener] connection accepted from 127.0.0.1:51787 #7 (3 connections now open)
2019-09-25T16:36:28.994+0530 I NETWORK  [conn6] received client metadata from 127.0.0.1:51786 conn6: { driver: { name: "NetworkInterfaceTL", version: "4.0.3" }, os: { type: "Darwin", name: "Mac OS X", architecture: "x86_64", version: "18.7.0" } }
2019-09-25T16:36:28.995+0530 I NETWORK  [conn7] received client metadata from 127.0.0.1:51787 conn7: { driver: { name: "NetworkInterfaceTL", version: "4.0.3" }, os: { type: "Darwin", name: "Mac OS X", architecture: "x86_64", version: "18.7.0" } }
2019-09-25T16:36:29.041+0530 I STORAGE  [conn1] Starting OplogTruncaterThread local.oplog.rs
2019-09-25T16:36:29.042+0530 I STORAGE  [conn1] The size storer reports that the oplog contains 0 records totaling to 0 bytes
2019-09-25T16:36:29.042+0530 I STORAGE  [conn1] Scanning the oplog to determine where to place markers for truncation
2019-09-25T16:36:29.152+0530 I REPL     [conn1] ******
2019-09-25T16:36:29.157+0530 I STORAGE  [conn1] createCollection: local.system.replset with generated UUID: 08216bfe-c5ca-4025-8426-cfd6662d9707
2019-09-25T16:36:29.245+0530 I STORAGE  [conn1] createCollection: admin.system.version with provided UUID: f5857381-7cf4-431b-b792-17c5bd7d4b94
2019-09-25T16:36:29.334+0530 I COMMAND  [conn1] setting featureCompatibilityVersion to 4.0
2019-09-25T16:36:29.336+0530 I NETWORK  [conn1] Skip closing connection for connection # 7
2019-09-25T16:36:29.336+0530 I NETWORK  [conn1] Skip closing connection for connection # 6
2019-09-25T16:36:29.337+0530 I NETWORK  [conn1] Skip closing connection for connection # 1
2019-09-25T16:36:29.339+0530 I REPL     [conn1] New replica set config in use: { _id: "conf", version: 1, configsvr: true, protocolVersion: 1, writeConcernMajorityJournalDefault: true, members: [ { _id: 0, host: "localhost:57040", arbiterOnly: false, buildIndexes: true, hidden: false, priority: 1.0, tags: {}, slaveDelay: 0, votes: 1 }, { _id: 1, host: "localhost:57041", arbiterOnly: false, buildIndexes: true, hidden: false, priority: 1.0, tags: {}, slaveDelay: 0, votes: 1 }, { _id: 2, host: "localhost:57042", arbiterOnly: false, buildIndexes: true, hidden: false, priority: 1.0, tags: {}, slaveDelay: 0, votes: 1 } ], settings: { chainingAllowed: true, heartbeatIntervalMillis: 2000, heartbeatTimeoutSecs: 10, electionTimeoutMillis: 10000, catchUpTimeoutMillis: -1, catchUpTakeoverDelayMillis: 30000, getLastErrorModes: {}, getLastErrorDefaults: { w: 1, wtimeout: 0 }, replicaSetId: ObjectId('5d8b4a34ec3bf68e0338e4c6') } }
2019-09-25T16:36:29.341+0530 I REPL     [conn1] This node is localhost:57040 in the config
2019-09-25T16:36:29.341+0530 I REPL     [conn1] transition to STARTUP2 from STARTUP
2019-09-25T16:36:29.342+0530 I REPL     [conn1] Starting replication storage threads
2019-09-25T16:36:29.344+0530 I REPL     [conn1] transition to RECOVERING from STARTUP2
2019-09-25T16:36:29.348+0530 I REPL     [conn1] Starting replication fetcher thread
2019-09-25T16:36:29.348+0530 I REPL     [conn1] Starting replication applier thread
2019-09-25T16:36:29.349+0530 I REPL     [replexec-0] Member localhost:57041 is now in state STARTUP
2019-09-25T16:36:29.349+0530 I REPL     [rsSync-0] Starting oplog application
2019-09-25T16:36:29.349+0530 I REPL     [conn1] Starting replication reporter thread
2019-09-25T16:36:29.352+0530 I REPL     [replexec-1] Member localhost:57042 is now in state STARTUP
2019-09-25T16:36:29.355+0530 I REPL     [rsSync-0] transition to SECONDARY from RECOVERING
2019-09-25T16:36:29.355+0530 I COMMAND  [conn1] command local.system.replset appName: "MongoDB Shell" command: replSetInitiate { replSetInitiate: { _id: "conf", members: [ { _id: 0.0, host: "localhost:57040" }, { _id: 1.0, host: "localhost:57041" }, { _id: 2.0, host: "localhost:57042" } ] }, lsid: { id: UUID("45a00b75-68df-431b-96e4-c1ef4b8ecaea") }, $clusterTime: { clusterTime: Timestamp(0, 0), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $db: "admin" } numYields:0 reslen:252 locks:{ Global: { acquireCount: { r: 15, w: 6, W: 2 }, acquireWaitCount: { W: 1 }, timeAcquiringMicros: { W: 376 } }, Database: { acquireCount: { r: 2, w: 3, W: 3 } }, Collection: { acquireCount: { r: 1, w: 2 } }, oplog: { acquireCount: { r: 1, w: 3 } } } protocol:op_msg 371ms
2019-09-25T16:36:29.357+0530 I REPL     [rsSync-0] Resetting sync source to empty, which was :27017
2019-09-25T16:36:30.998+0530 I NETWORK  [listener] connection accepted from 127.0.0.1:51797 #8 (4 connections now open)
2019-09-25T16:36:30.999+0530 I NETWORK  [listener] connection accepted from 127.0.0.1:51798 #9 (5 connections now open)
2019-09-25T16:36:30.999+0530 I NETWORK  [conn8] end connection 127.0.0.1:51797 (4 connections now open)
2019-09-25T16:36:31.000+0530 I NETWORK  [conn9] end connection 127.0.0.1:51798 (3 connections now open)
2019-09-25T16:36:31.364+0530 I REPL     [replexec-1] Member localhost:57042 is now in state STARTUP2
2019-09-25T16:36:31.370+0530 I REPL     [replexec-0] Member localhost:57041 is now in state STARTUP2
2019-09-25T16:36:31.664+0530 I NETWORK  [listener] connection accepted from 127.0.0.1:51807 #10 (4 connections now open)
2019-09-25T16:36:31.674+0530 I NETWORK  [conn10] received client metadata from 127.0.0.1:51807 conn10: { driver: { name: "NetworkInterfaceTL", version: "4.0.3" }, os: { type: "Darwin", name: "Mac OS X", architecture: "x86_64", version: "18.7.0" } }
2019-09-25T16:36:31.687+0530 I NETWORK  [listener] connection accepted from 127.0.0.1:51808 #11 (5 connections now open)
2019-09-25T16:36:31.694+0530 I NETWORK  [conn11] received client metadata from 127.0.0.1:51808 conn11: { driver: { name: "NetworkInterfaceTL", version: "4.0.3" }, os: { type: "Darwin", name: "Mac OS X", architecture: "x86_64", version: "18.7.0" } }
2019-09-25T16:36:31.825+0530 I NETWORK  [listener] connection accepted from 127.0.0.1:51809 #12 (6 connections now open)
2019-09-25T16:36:31.825+0530 I NETWORK  [conn12] received client metadata from 127.0.0.1:51809 conn12: { driver: { name: "NetworkInterfaceTL", version: "4.0.3" }, os: { type: "Darwin", name: "Mac OS X", architecture: "x86_64", version: "18.7.0" } }
2019-09-25T16:36:31.840+0530 I NETWORK  [listener] connection accepted from 127.0.0.1:51810 #13 (7 connections now open)
2019-09-25T16:36:31.841+0530 I NETWORK  [conn13] received client metadata from 127.0.0.1:51810 conn13: { driver: { name: "NetworkInterfaceTL", version: "4.0.3" }, os: { type: "Darwin", name: "Mac OS X", architecture: "x86_64", version: "18.7.0" } }
2019-09-25T16:36:32.369+0530 I REPL     [replexec-0] Member localhost:57042 is now in state SECONDARY
2019-09-25T16:36:32.370+0530 I REPL     [replexec-0] Member localhost:57041 is now in state SECONDARY
2019-09-25T16:36:40.186+0530 I REPL     [replexec-0] Starting an election, since we've seen no PRIMARY in the past 10000ms
2019-09-25T16:36:40.187+0530 I REPL     [replexec-0] conducting a dry run election to see if we could be elected. current term: 0
2019-09-25T16:36:40.189+0530 I REPL     [replexec-1] VoteRequester(term 0 dry run) received a yes vote from localhost:57041; response message: { term: 0, voteGranted: true, reason: "", ok: 1.0, operationTime: Timestamp(1569409589, 1), $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('000000000000000000000000') }, lastCommittedOpTime: Timestamp(0, 0), $clusterTime: { clusterTime: Timestamp(1569409589, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } } }
2019-09-25T16:36:40.190+0530 I REPL     [replexec-0] dry election run succeeded, running for election in term 1
2019-09-25T16:36:40.190+0530 I STORAGE  [replexec-0] createCollection: local.replset.election with generated UUID: 738a7a42-6f9e-4880-9ab2-e28525ac9530
2019-09-25T16:36:40.415+0530 I REPL     [replexec-1] VoteRequester(term 1) received a yes vote from localhost:57041; response message: { term: 1, voteGranted: true, reason: "", ok: 1.0, operationTime: Timestamp(1569409589, 1), $gleStats: { lastOpTime: Timestamp(0, 0), electionId: ObjectId('000000000000000000000000') }, lastCommittedOpTime: Timestamp(0, 0), $clusterTime: { clusterTime: Timestamp(1569409589, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } } }
2019-09-25T16:36:40.422+0530 I ASIO     [Replication] Connecting to localhost:57042
2019-09-25T16:36:40.429+0530 I REPL     [replexec-1] election succeeded, assuming primary role in term 1
2019-09-25T16:36:40.430+0530 I REPL     [replexec-1] transition to PRIMARY from SECONDARY
2019-09-25T16:36:40.431+0530 I REPL     [replexec-1] Resetting sync source to empty, which was :27017
2019-09-25T16:36:40.432+0530 I ASIO     [Replication] Ending idle connection to host localhost:57042 because the pool meets constraints; 1 connections to that host remain open
2019-09-25T16:36:40.432+0530 I REPL     [replexec-1] Entering primary catch-up mode.
2019-09-25T16:36:40.433+0530 I ASIO     [Replication] Connecting to localhost:57042
2019-09-25T16:36:40.435+0530 I REPL     [replexec-2] Caught up to the latest optime known via heartbeats after becoming primary.
2019-09-25T16:36:40.435+0530 I REPL     [replexec-2] Exited primary catch-up mode.
2019-09-25T16:36:40.436+0530 I REPL     [replexec-2] Stopping replication producer
2019-09-25T16:36:41.397+0530 I STORAGE  [rsSync-0] createCollection: config.chunks with generated UUID: a29ae56a-177b-4904-b404-f0f9bbf669e6
2019-09-25T16:36:41.517+0530 I INDEX    [rsSync-0] build index on: config.chunks properties: { v: 2, unique: true, key: { ns: 1, min: 1 }, name: "ns_1_min_1", ns: "config.chunks" }
2019-09-25T16:36:41.521+0530 I INDEX    [rsSync-0] 	 building index using bulk method; build may temporarily use up to 500 megabytes of RAM
2019-09-25T16:36:41.533+0530 I INDEX    [rsSync-0] build index done.  scanned 0 total records. 0 secs
2019-09-25T16:36:41.534+0530 I COMMAND  [rsSync-0] command config.$cmd command: createIndexes { createIndexes: "chunks", indexes: [ { name: "ns_1_min_1", key: { ns: 1, min: 1 }, unique: true } ], $db: "config" } numYields:0 reslen:348 locks:{ Global: { acquireCount: { r: 15, w: 7, W: 1 } }, Database: { acquireCount: { r: 4, w: 7, W: 1 } }, Collection: { acquireCount: { r: 3, w: 3 } }, oplog: { acquireCount: { r: 1, w: 4 } } } protocol:op_msg 136ms
2019-09-25T16:36:41.570+0530 I INDEX    [rsSync-0] build index on: config.chunks properties: { v: 2, unique: true, key: { ns: 1, shard: 1, min: 1 }, name: "ns_1_shard_1_min_1", ns: "config.chunks" }
2019-09-25T16:36:41.574+0530 I INDEX    [rsSync-0] 	 building index using bulk method; build may temporarily use up to 500 megabytes of RAM
2019-09-25T16:36:41.585+0530 I INDEX    [rsSync-0] build index done.  scanned 0 total records. 0 secs
2019-09-25T16:36:41.624+0530 I INDEX    [rsSync-0] build index on: config.chunks properties: { v: 2, unique: true, key: { ns: 1, lastmod: 1 }, name: "ns_1_lastmod_1", ns: "config.chunks" }
2019-09-25T16:36:41.628+0530 I INDEX    [rsSync-0] 	 building index using bulk method; build may temporarily use up to 500 megabytes of RAM
2019-09-25T16:36:41.639+0530 I INDEX    [rsSync-0] build index done.  scanned 0 total records. 0 secs
2019-09-25T16:36:41.640+0530 I STORAGE  [rsSync-0] createCollection: config.migrations with generated UUID: 95e01ff7-4fc2-408e-a628-8b052b1b0d88
2019-09-25T16:36:41.696+0530 I NETWORK  [conn10] end connection 127.0.0.1:51807 (6 connections now open)
2019-09-25T16:36:41.765+0530 I INDEX    [rsSync-0] build index on: config.migrations properties: { v: 2, unique: true, key: { ns: 1, min: 1 }, name: "ns_1_min_1", ns: "config.migrations" }
2019-09-25T16:36:41.769+0530 I INDEX    [rsSync-0] 	 building index using bulk method; build may temporarily use up to 500 megabytes of RAM
2019-09-25T16:36:41.781+0530 I INDEX    [rsSync-0] build index done.  scanned 0 total records. 0 secs
2019-09-25T16:36:41.782+0530 I COMMAND  [rsSync-0] command config.$cmd command: createIndexes { createIndexes: "migrations", indexes: [ { name: "ns_1_min_1", key: { ns: 1, min: 1 }, unique: true } ], $db: "config" } numYields:0 reslen:348 locks:{ Global: { acquireCount: { r: 28, w: 20, W: 1 } }, Database: { acquireCount: { r: 4, w: 20, W: 4 } }, Collection: { acquireCount: { r: 3, w: 9 } }, oplog: { acquireCount: { r: 1, w: 11 } } } protocol:op_msg 141ms
2019-09-25T16:36:41.783+0530 I STORAGE  [rsSync-0] createCollection: config.shards with generated UUID: ab66f73e-db70-4fc2-9ee2-94eb15dd4ac0
2019-09-25T16:36:41.850+0530 I NETWORK  [conn12] end connection 127.0.0.1:51809 (5 connections now open)
2019-09-25T16:36:41.906+0530 I INDEX    [rsSync-0] build index on: config.shards properties: { v: 2, unique: true, key: { host: 1 }, name: "host_1", ns: "config.shards" }
2019-09-25T16:36:41.910+0530 I INDEX    [rsSync-0] 	 building index using bulk method; build may temporarily use up to 500 megabytes of RAM
2019-09-25T16:36:41.922+0530 I INDEX    [rsSync-0] build index done.  scanned 0 total records. 0 secs
2019-09-25T16:36:41.922+0530 I COMMAND  [rsSync-0] command config.$cmd command: createIndexes { createIndexes: "shards", indexes: [ { name: "host_1", key: { host: 1 }, unique: true } ], $db: "config" } numYields:0 reslen:348 locks:{ Global: { acquireCount: { r: 33, w: 25, W: 1 } }, Database: { acquireCount: { r: 4, w: 25, W: 5 } }, Collection: { acquireCount: { r: 3, w: 11 } }, oplog: { acquireCount: { r: 1, w: 14 } } } protocol:op_msg 139ms
2019-09-25T16:36:41.923+0530 I STORAGE  [rsSync-0] createCollection: config.locks with generated UUID: 2593e2cf-81cd-46e5-9de0-e1eceef42f19
2019-09-25T16:36:42.059+0530 I INDEX    [rsSync-0] build index on: config.locks properties: { v: 2, key: { ts: 1 }, name: "ts_1", ns: "config.locks" }
2019-09-25T16:36:42.063+0530 I INDEX    [rsSync-0] 	 building index using bulk method; build may temporarily use up to 500 megabytes of RAM
2019-09-25T16:36:42.078+0530 I INDEX    [rsSync-0] build index done.  scanned 0 total records. 0 secs
2019-09-25T16:36:42.079+0530 I COMMAND  [rsSync-0] command config.$cmd command: createIndexes { createIndexes: "locks", indexes: [ { name: "ts_1", key: { ts: 1 }, unique: false } ], $db: "config" } numYields:0 reslen:348 locks:{ Global: { acquireCount: { r: 38, w: 30, W: 1 } }, Database: { acquireCount: { r: 4, w: 30, W: 6 } }, Collection: { acquireCount: { r: 3, w: 13 } }, oplog: { acquireCount: { r: 1, w: 17 } } } protocol:op_msg 155ms
2019-09-25T16:36:42.115+0530 I INDEX    [rsSync-0] build index on: config.locks properties: { v: 2, key: { state: 1, process: 1 }, name: "state_1_process_1", ns: "config.locks" }
2019-09-25T16:36:42.118+0530 I INDEX    [rsSync-0] 	 building index using bulk method; build may temporarily use up to 500 megabytes of RAM
2019-09-25T16:36:42.131+0530 I INDEX    [rsSync-0] build index done.  scanned 0 total records. 0 secs
2019-09-25T16:36:42.132+0530 I STORAGE  [rsSync-0] createCollection: config.lockpings with generated UUID: 3805cdd9-ed71-479c-b735-93da5d58ec8f
2019-09-25T16:36:42.253+0530 I INDEX    [rsSync-0] build index on: config.lockpings properties: { v: 2, key: { ping: 1 }, name: "ping_1", ns: "config.lockpings" }
2019-09-25T16:36:42.257+0530 I INDEX    [rsSync-0] 	 building index using bulk method; build may temporarily use up to 500 megabytes of RAM
2019-09-25T16:36:42.269+0530 I INDEX    [rsSync-0] build index done.  scanned 0 total records. 0 secs
2019-09-25T16:36:42.269+0530 I COMMAND  [rsSync-0] command config.$cmd command: createIndexes { createIndexes: "lockpings", indexes: [ { name: "ping_1", key: { ping: 1 }, unique: false } ], $db: "config" } numYields:0 reslen:348 locks:{ Global: { acquireCount: { r: 47, w: 39, W: 1 } }, Database: { acquireCount: { r: 4, w: 39, W: 8 } }, Collection: { acquireCount: { r: 3, w: 17 } }, oplog: { acquireCount: { r: 1, w: 22 } } } protocol:op_msg 137ms
2019-09-25T16:36:42.270+0530 I STORAGE  [rsSync-0] createCollection: config.tags with generated UUID: 62d962da-be89-4efe-b50d-0db30ac785b1
2019-09-25T16:36:42.380+0530 I INDEX    [rsSync-0] build index on: config.tags properties: { v: 2, unique: true, key: { ns: 1, min: 1 }, name: "ns_1_min_1", ns: "config.tags" }
2019-09-25T16:36:42.384+0530 I INDEX    [rsSync-0] 	 building index using bulk method; build may temporarily use up to 500 megabytes of RAM
2019-09-25T16:36:42.396+0530 I INDEX    [rsSync-0] build index done.  scanned 0 total records. 0 secs
2019-09-25T16:36:42.396+0530 I COMMAND  [rsSync-0] command config.$cmd command: createIndexes { createIndexes: "tags", indexes: [ { name: "ns_1_min_1", key: { ns: 1, min: 1 }, unique: true } ], $db: "config" } numYields:0 reslen:348 locks:{ Global: { acquireCount: { r: 52, w: 44, W: 1 } }, Database: { acquireCount: { r: 4, w: 44, W: 9 } }, Collection: { acquireCount: { r: 3, w: 19 } }, oplog: { acquireCount: { r: 1, w: 25 } } } protocol:op_msg 126ms
2019-09-25T16:36:42.432+0530 I INDEX    [rsSync-0] build index on: config.tags properties: { v: 2, key: { ns: 1, tag: 1 }, name: "ns_1_tag_1", ns: "config.tags" }
2019-09-25T16:36:42.436+0530 I INDEX    [rsSync-0] 	 building index using bulk method; build may temporarily use up to 500 megabytes of RAM
2019-09-25T16:36:42.446+0530 I INDEX    [rsSync-0] build index done.  scanned 0 total records. 0 secs
2019-09-25T16:36:42.448+0530 I STORAGE  [rsSync-0] createCollection: config.version with generated UUID: a525b8ed-ec73-4bf7-bbf9-230a507e4461
2019-09-25T16:36:42.551+0530 I COMMAND  [rsSync-0] command config.version command: insert { insert: "version", bypassDocumentValidation: false, ordered: true, documents: [ { _id: 1, minCompatibleVersion: 5, currentVersion: 6, clusterId: ObjectId('5d8b4a42ec3bf68e0338e52b') } ], writeConcern: { w: 1, wtimeout: 0 }, allowImplicitCollectionCreation: true, $db: "config" } ninserted:1 keysInserted:1 numYields:0 reslen:339 locks:{ Global: { acquireCount: { r: 62, w: 53, W: 1 } }, Database: { acquireCount: { r: 5, w: 52, W: 11 } }, Collection: { acquireCount: { r: 4, w: 23 } }, oplog: { acquireCount: { r: 1, w: 29 } } } protocol:op_msg 102ms
2019-09-25T16:36:42.555+0530 I SHARDING [Balancer] CSRS balancer is starting
2019-09-25T16:36:42.555+0530 I STORAGE  [rsSync-0] createCollection: config.transactions with generated UUID: 8b1ef7bc-2c42-47e9-8811-2d2c2a58fd5f
2019-09-25T16:36:42.641+0530 I REPL     [rsSync-0] transition to primary complete; database writes are now permitted
2019-09-25T16:36:42.652+0530 I COMMAND  [conn11] command local.oplog.rs command: find { find: "oplog.rs", limit: 1, sort: { $natural: 1 }, projection: { ts: 1, t: 1 }, $readPreference: { mode: "secondaryPreferred" }, $clusterTime: { clusterTime: Timestamp(1569409601, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $db: "local" } planSummary: COLLSCAN keysExamined:0 docsExamined:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:337 locks:{ Global: { acquireCount: { r: 1 }, acquireWaitCount: { r: 1 }, timeAcquiringMicros: { r: 678652 } }, Database: { acquireCount: { r: 1 } }, oplog: { acquireCount: { r: 1 } } } protocol:op_msg 685ms
2019-09-25T16:36:42.652+0530 I COMMAND  [conn13] command local.oplog.rs command: find { find: "oplog.rs", limit: 1, sort: { $natural: 1 }, projection: { ts: 1, t: 1 }, $readPreference: { mode: "secondaryPreferred" }, $clusterTime: { clusterTime: Timestamp(1569409601, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $db: "local" } planSummary: COLLSCAN keysExamined:0 docsExamined:1 cursorExhausted:1 numYields:0 nreturned:1 reslen:337 locks:{ Global: { acquireCount: { r: 1 }, acquireWaitCount: { r: 1 }, timeAcquiringMicros: { r: 593579 } }, Database: { acquireCount: { r: 1 } }, oplog: { acquireCount: { r: 1 } } } protocol:op_msg 600ms
2019-09-25T16:36:42.660+0530 I NETWORK  [listener] connection accepted from 127.0.0.1:51857 #16 (6 connections now open)
2019-09-25T16:36:42.672+0530 I NETWORK  [conn16] received client metadata from 127.0.0.1:51857 conn16: { driver: { name: "NetworkInterfaceTL", version: "4.0.3" }, os: { type: "Darwin", name: "Mac OS X", architecture: "x86_64", version: "18.7.0" } }
2019-09-25T16:36:42.672+0530 I NETWORK  [listener] connection accepted from 127.0.0.1:51858 #17 (7 connections now open)
2019-09-25T16:36:42.682+0530 I STORAGE  [conn16] Triggering the first stable checkpoint. Initial Data: Timestamp(1569409589, 1) PrevStable: Timestamp(0, 0) CurrStable: Timestamp(1569409601, 1)
2019-09-25T16:36:42.682+0530 I NETWORK  [conn17] received client metadata from 127.0.0.1:51858 conn17: { driver: { name: "NetworkInterfaceTL", version: "4.0.3" }, os: { type: "Darwin", name: "Mac OS X", architecture: "x86_64", version: "18.7.0" } }
2019-09-25T16:36:44.811+0530 I SHARDING [Balancer] CSRS balancer thread is recovering
2019-09-25T16:36:44.814+0530 I STORAGE  [monitoring keys for HMAC] createCollection: admin.system.keys with generated UUID: 113eca38-f517-4e05-aca2-f27bee381086
2019-09-25T16:36:44.821+0530 I SHARDING [Balancer] CSRS balancer thread is recovered
2019-09-25T16:36:45.484+0530 I COMMAND  [monitoring keys for HMAC] command admin.system.keys command: insert { insert: "system.keys", bypassDocumentValidation: false, ordered: true, documents: [ { _id: 6740562914618376207, purpose: "HMAC", key: BinData(0, 18F28A772BC7A58D3547402C0F38808400923214), expiresAt: Timestamp(1577185602, 0) } ], writeConcern: { w: "majority", wtimeout: 15000 }, allowImplicitCollectionCreation: true, $db: "admin" } ninserted:1 keysInserted:1 numYields:0 reslen:339 locks:{ Global: { acquireCount: { r: 6, w: 5 } }, Database: { acquireCount: { r: 1, w: 2, W: 3 } }, Collection: { acquireCount: { r: 1, w: 2 } }, oplog: { acquireCount: { w: 2 } } } protocol:op_msg 669ms
2019-09-25T16:36:48.839+0530 W SHARDING [replSetDistLockPinger] pinging failed for distributed lock pinger :: caused by :: LockStateChangeFailed: findAndModify query predicate didn't match any lock document
2019-09-25T16:36:50.290+0530 I ASIO     [Replication] Ending connection to host localhost:57042 due to bad connection status; 1 connections to that host remain open
2019-09-25T16:37:39.854+0530 I NETWORK  [conn1] end connection 127.0.0.1:50297 (6 connections now open)
2019-09-25T16:41:18.963+0530 I CONTROL  [LogicalSessionCacheRefresh] Failed to create config.system.sessions: Cannot create config.system.sessions until there are shards, will try again at the next refresh interval
2019-09-25T16:41:18.968+0530 I CONTROL  [LogicalSessionCacheRefresh] Sessions collection is not set up; waiting until next sessions refresh interval: Cannot create config.system.sessions until there are shards
2019-09-25T16:46:18.965+0530 I SH_REFR  [ConfigServerCatalogCacheLoader-1] Refresh for collection config.system.sessions took 0 ms and found the collection is not sharded
2019-09-25T16:46:18.968+0530 I CONTROL  [LogicalSessionCacheRefresh] Failed to create config.system.sessions: Cannot create config.system.sessions until there are shards, will try again at the next refresh interval
2019-09-25T16:46:18.969+0530 I CONTROL  [LogicalSessionCacheRefresh] Sessions collection is not set up; waiting until next sessions refresh interval: Cannot create config.system.sessions until there are shards
2019-09-25T16:51:18.973+0530 I SH_REFR  [ConfigServerCatalogCacheLoader-2] Refresh for collection config.system.sessions took 0 ms and found the collection is not sharded
2019-09-25T16:51:18.974+0530 I CONTROL  [LogicalSessionCacheRefresh] Failed to create config.system.sessions: Cannot create config.system.sessions until there are shards, will try again at the next refresh interval
2019-09-25T16:51:18.975+0530 I CONTROL  [LogicalSessionCacheRefresh] Sessions collection is not set up; waiting until next sessions refresh interval: Cannot create config.system.sessions until there are shards
2019-09-25T16:52:07.869+0530 I NETWORK  [listener] connection accepted from 127.0.0.1:55655 #18 (7 connections now open)
2019-09-25T16:52:07.870+0530 I NETWORK  [conn18] received client metadata from 127.0.0.1:55655 conn18: { driver: { name: "MongoDB Internal Client", version: "4.0.3" }, os: { type: "Darwin", name: "Mac OS X", architecture: "x86_64", version: "18.7.0" } }
2019-09-25T16:52:07.874+0530 I NETWORK  [listener] connection accepted from 127.0.0.1:55657 #19 (8 connections now open)
2019-09-25T16:52:07.875+0530 I NETWORK  [listener] connection accepted from 127.0.0.1:55658 #20 (9 connections now open)
2019-09-25T16:52:07.875+0530 I NETWORK  [conn19] received client metadata from 127.0.0.1:55657 conn19: { driver: { name: "NetworkInterfaceTL", version: "4.0.3" }, os: { type: "Darwin", name: "Mac OS X", architecture: "x86_64", version: "18.7.0" } }
2019-09-25T16:52:07.876+0530 I NETWORK  [conn20] received client metadata from 127.0.0.1:55658 conn20: { driver: { name: "NetworkInterfaceTL", version: "4.0.3" }, os: { type: "Darwin", name: "Mac OS X", architecture: "x86_64", version: "18.7.0" } }
2019-09-25T16:52:07.878+0530 I NETWORK  [listener] connection accepted from 127.0.0.1:55660 #21 (10 connections now open)
2019-09-25T16:52:07.888+0530 I NETWORK  [listener] connection accepted from 127.0.0.1:55661 #22 (11 connections now open)
2019-09-25T16:52:07.888+0530 I NETWORK  [conn21] received client metadata from 127.0.0.1:55660 conn21: { driver: { name: "NetworkInterfaceTL", version: "4.0.3" }, os: { type: "Darwin", name: "Mac OS X", architecture: "x86_64", version: "18.7.0" } }
2019-09-25T16:52:07.896+0530 I NETWORK  [conn22] received client metadata from 127.0.0.1:55661 conn22: { driver: { name: "NetworkInterfaceTL", version: "4.0.3" }, os: { type: "Darwin", name: "Mac OS X", architecture: "x86_64", version: "18.7.0" } }
2019-09-25T16:52:08.106+0530 I STORAGE  [conn22] createCollection: config.mongos with generated UUID: b452eb81-8908-497c-af8b-3e07d7b93c3f
2019-09-25T16:52:08.345+0530 I COMMAND  [conn22] command config.$cmd command: update { update: "mongos", bypassDocumentValidation: false, ordered: true, updates: [ { q: { _id: "ShailendraMishra-anmepls-MacBook-Pro.local:21010" }, u: { $set: { _id: "ShailendraMishra-anmepls-MacBook-Pro.local:21010", ping: new Date(1569410527913), up: 0, waiting: true, mongoVersion: "4.0.3", advisoryHostFQDNs: [ "shailendramishra-anmepls-macbook-pro.local" ] } }, multi: false, upsert: true } ], writeConcern: { w: "majority", wtimeout: 15000 }, allowImplicitCollectionCreation: true, maxTimeMS: 30000, $replData: 1, $clusterTime: { clusterTime: Timestamp(1569410527, 1), signature: { hash: BinData(0, 2FC3C30E5012138081F3B5934E0F1470CC676666), keyId: 6740562914618376207 } }, $configServerState: { opTime: { ts: Timestamp(1569410527, 1), t: 1 } }, $db: "config" } numYields:0 reslen:652 locks:{ Global: { acquireCount: { r: 5, w: 5 } }, Database: { acquireCount: { w: 4, W: 1 } }, Collection: { acquireCount: { w: 2 } }, oplog: { acquireCount: { w: 2 } } } protocol:op_msg 239ms
2019-09-25T16:53:07.881+0530 I NETWORK  [conn20] end connection 127.0.0.1:55658 (10 connections now open)
2019-09-25T16:53:07.912+0530 I NETWORK  [conn21] end connection 127.0.0.1:55660 (9 connections now open)
2019-09-25T16:53:37.931+0530 I NETWORK  [conn19] end connection 127.0.0.1:55657 (8 connections now open)
2019-09-25T16:53:57.919+0530 I NETWORK  [conn22] end connection 127.0.0.1:55661 (7 connections now open)
2019-09-25T16:53:57.924+0530 I NETWORK  [conn18] end connection 127.0.0.1:55655 (6 connections now open)
2019-09-25T16:54:21.762+0530 I NETWORK  [listener] connection accepted from 127.0.0.1:56212 #23 (7 connections now open)
2019-09-25T16:54:21.762+0530 I NETWORK  [conn23] received client metadata from 127.0.0.1:56212 conn23: { driver: { name: "MongoDB Internal Client", version: "4.0.3" }, os: { type: "Darwin", name: "Mac OS X", architecture: "x86_64", version: "18.7.0" } }
2019-09-25T16:54:21.765+0530 I NETWORK  [listener] connection accepted from 127.0.0.1:56217 #24 (8 connections now open)
2019-09-25T16:54:21.766+0530 I NETWORK  [listener] connection accepted from 127.0.0.1:56218 #25 (9 connections now open)
2019-09-25T16:54:21.766+0530 I NETWORK  [conn24] received client metadata from 127.0.0.1:56217 conn24: { driver: { name: "NetworkInterfaceTL", version: "4.0.3" }, os: { type: "Darwin", name: "Mac OS X", architecture: "x86_64", version: "18.7.0" } }
2019-09-25T16:54:21.767+0530 I NETWORK  [conn25] received client metadata from 127.0.0.1:56218 conn25: { driver: { name: "NetworkInterfaceTL", version: "4.0.3" }, os: { type: "Darwin", name: "Mac OS X", architecture: "x86_64", version: "18.7.0" } }
2019-09-25T16:55:21.778+0530 I NETWORK  [conn25] end connection 127.0.0.1:56218 (8 connections now open)
2019-09-25T16:56:18.982+0530 I SH_REFR  [ConfigServerCatalogCacheLoader-3] Refresh for collection config.system.sessions took 0 ms and found the collection is not sharded
2019-09-25T16:56:18.984+0530 I CONTROL  [LogicalSessionCacheRefresh] Failed to create config.system.sessions: Cannot create config.system.sessions until there are shards, will try again at the next refresh interval
2019-09-25T16:56:18.984+0530 I CONTROL  [LogicalSessionCacheRefresh] Sessions collection is not set up; waiting until next sessions refresh interval: Cannot create config.system.sessions until there are shards
2019-09-25T16:57:09.329+0530 I NETWORK  [conn24] Starting new replica set monitor for shard1/localhost:27017
2019-09-25T16:57:09.332+0530 I NETWORK  [ReplicaSetMonitor-TaskExecutor] Successfully connected to localhost:27017 (1 connections now open to localhost:27017 with a 5 second timeout)
2019-09-25T16:57:09.333+0530 I NETWORK  [ReplicaSetMonitor-TaskExecutor] changing hosts to shard1/localhost:27017,localhost:27018,localhost:27019 from shard1/localhost:27017
2019-09-25T16:57:09.333+0530 I ASIO     [AddShard-TaskExecutor] Connecting to localhost:27017
2019-09-25T16:57:09.337+0530 I NETWORK  [ReplicaSetMonitor-TaskExecutor] Successfully connected to localhost:27019 (1 connections now open to localhost:27019 with a 5 second timeout)
2019-09-25T16:57:09.339+0530 I NETWORK  [ReplicaSetMonitor-TaskExecutor] Successfully connected to localhost:27018 (1 connections now open to localhost:27018 with a 5 second timeout)
2019-09-25T16:57:09.536+0530 I SHARDING [conn24] going to insert new entry for shard into config.shards: { _id: "shard1", host: "shard1/localhost:27017,localhost:27018,localhost:27019", state: 1 }
2019-09-25T16:57:09.567+0530 I STORAGE  [conn24] createCollection: config.changelog with generated UUID: 126cc3db-e209-44ed-84eb-3b1a81dc5e95
2019-09-25T16:57:09.804+0530 I COMMAND  [conn24] command config.changelog appName: "MongoDB Shell" command: create { create: "changelog", capped: true, size: 209715200, writeConcern: { w: "majority", wtimeout: 15000 }, $db: "config" } numYields:0 reslen:272 locks:{ Global: { acquireCount: { r: 6, w: 4 } }, Database: { acquireCount: { r: 2, w: 3, W: 1 } }, Collection: { acquireCount: { r: 2, w: 1 } }, Mutex: { acquireCount: { r: 1, W: 1 } }, oplog: { acquireCount: { w: 2 } } } protocol:op_msg 236ms
2019-09-25T16:57:09.810+0530 I SHARDING [conn24] about to log metadata event into changelog: { _id: "ShailendraMishra-anmepls-MacBook-Pro.local-2019-09-25T16:57:09.806+0530-5d8b4f0dec3bf68e0338f5eb", server: "ShailendraMishra-anmepls-MacBook-Pro.local", clientAddr: "127.0.0.1:56217", time: new Date(1569410829806), what: "addShard", ns: "", details: { name: "shard1", host: "shard1/localhost:27017" } }
2019-09-25T16:57:09.840+0530 I COMMAND  [conn24] command admin.$cmd appName: "MongoDB Shell" command: _configsvrAddShard { _configsvrAddShard: "shard1/localhost:27017", lsid: { id: UUID("659ad293-65be-4a29-bd9e-60f6c7287f91") }, writeConcern: { w: "majority", wtimeout: 60000 }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1569410824, 1), signature: { hash: BinData(0, F36C032101F97E4AE71D522041EBB41C04659D57), keyId: 6740562914618376207 } }, $client: { application: { name: "MongoDB Shell" }, driver: { name: "MongoDB Internal Client", version: "4.0.3" }, os: { type: "Darwin", name: "Mac OS X", architecture: "x86_64", version: "18.7.0" }, mongos: { host: "ShailendraMishra-anmepls-MacBook-Pro.local:21010", client: "127.0.0.1:56588", version: "4.0.3" } }, $configServerState: { opTime: { ts: Timestamp(1569410824, 1), t: 1 } }, $db: "admin" } numYields:0 reslen:501 locks:{ Global: { acquireCount: { r: 9, w: 6 } }, Database: { acquireCount: { r: 3, w: 5, W: 1 } }, Collection: { acquireCount: { r: 3, w: 2 } }, Metadata: { acquireCount: { W: 1 } }, Mutex: { acquireCount: { r: 1, W: 1 } }, oplog: { acquireCount: { w: 3 } } } protocol:op_msg 511ms
2019-09-25T16:57:15.349+0530 I ASIO     [ShardRegistry] Connecting to localhost:27017
2019-09-25T16:57:17.465+0530 I NETWORK  [conn24] Starting new replica set monitor for shard2/localhost:37017
2019-09-25T16:57:17.472+0530 I NETWORK  [conn24] Successfully connected to localhost:37017 (1 connections now open to localhost:37017 with a 5 second timeout)
2019-09-25T16:57:17.474+0530 I NETWORK  [conn24] Successfully connected to localhost:37019 (1 connections now open to localhost:37019 with a 5 second timeout)
2019-09-25T16:57:17.474+0530 I NETWORK  [conn24] changing hosts to shard2/localhost:37017,localhost:37018,localhost:37019 from shard2/localhost:37017
2019-09-25T16:57:17.475+0530 I ASIO     [AddShard-TaskExecutor] Connecting to localhost:37019
2019-09-25T16:57:17.476+0530 I NETWORK  [ReplicaSetMonitor-TaskExecutor] Successfully connected to localhost:37018 (1 connections now open to localhost:37018 with a 5 second timeout)
2019-09-25T16:57:17.628+0530 I SHARDING [conn24] going to insert new entry for shard into config.shards: { _id: "shard2", host: "shard2/localhost:37017,localhost:37018,localhost:37019", state: 1 }
2019-09-25T16:57:17.645+0530 I SHARDING [conn24] about to log metadata event into changelog: { _id: "ShailendraMishra-anmepls-MacBook-Pro.local-2019-09-25T16:57:17.644+0530-5d8b4f15ec3bf68e0338f614", server: "ShailendraMishra-anmepls-MacBook-Pro.local", clientAddr: "127.0.0.1:56217", time: new Date(1569410837644), what: "addShard", ns: "", details: { name: "shard2", host: "shard2/localhost:37017" } }
2019-09-25T16:57:17.701+0530 I COMMAND  [conn24] command admin.$cmd appName: "MongoDB Shell" command: _configsvrAddShard { _configsvrAddShard: "shard2/localhost:37017", lsid: { id: UUID("659ad293-65be-4a29-bd9e-60f6c7287f91") }, writeConcern: { w: "majority", wtimeout: 60000 }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1569410834, 1), signature: { hash: BinData(0, AAF815649A8BDF5774C9DB961FD242C4219A07C3), keyId: 6740562914618376207 } }, $client: { application: { name: "MongoDB Shell" }, driver: { name: "MongoDB Internal Client", version: "4.0.3" }, os: { type: "Darwin", name: "Mac OS X", architecture: "x86_64", version: "18.7.0" }, mongos: { host: "ShailendraMishra-anmepls-MacBook-Pro.local:21010", client: "127.0.0.1:56588", version: "4.0.3" } }, $configServerState: { opTime: { ts: Timestamp(1569410834, 1), t: 1 } }, $db: "admin" } numYields:0 reslen:501 locks:{ Global: { acquireCount: { r: 7, w: 4 } }, Database: { acquireCount: { r: 3, w: 4 } }, Collection: { acquireCount: { r: 3, w: 2 } }, Metadata: { acquireCount: { W: 1 } }, Mutex: { acquireCount: { r: 1, W: 1 } }, oplog: { acquireCount: { w: 2 } } } protocol:op_msg 236ms
2019-09-25T16:57:22.953+0530 I NETWORK  [conn24] Starting new replica set monitor for shard3/localhost:47017
2019-09-25T16:57:22.960+0530 I NETWORK  [conn24] Successfully connected to localhost:47017 (1 connections now open to localhost:47017 with a 5 second timeout)
2019-09-25T16:57:22.961+0530 I NETWORK  [conn24] changing hosts to shard3/localhost:47017,localhost:47018,localhost:47019 from shard3/localhost:47017
2019-09-25T16:57:22.961+0530 I ASIO     [AddShard-TaskExecutor] Connecting to localhost:47017
2019-09-25T16:57:22.963+0530 I NETWORK  [ReplicaSetMonitor-TaskExecutor] Successfully connected to localhost:47018 (1 connections now open to localhost:47018 with a 5 second timeout)
2019-09-25T16:57:22.976+0530 I NETWORK  [ReplicaSetMonitor-TaskExecutor] Successfully connected to localhost:47019 (1 connections now open to localhost:47019 with a 5 second timeout)
2019-09-25T16:57:23.187+0530 I SHARDING [conn24] going to insert new entry for shard into config.shards: { _id: "shard3", host: "shard3/localhost:47017,localhost:47018,localhost:47019", state: 1 }
2019-09-25T16:57:23.189+0530 I SHARDING [conn24] about to log metadata event into changelog: { _id: "ShailendraMishra-anmepls-MacBook-Pro.local-2019-09-25T16:57:23.189+0530-5d8b4f1bec3bf68e0338f645", server: "ShailendraMishra-anmepls-MacBook-Pro.local", clientAddr: "127.0.0.1:56217", time: new Date(1569410843189), what: "addShard", ns: "", details: { name: "shard3", host: "shard3/localhost:47017" } }
2019-09-25T16:57:23.249+0530 I COMMAND  [conn24] command admin.$cmd appName: "MongoDB Shell" command: _configsvrAddShard { _configsvrAddShard: "shard3/localhost:47017", lsid: { id: UUID("659ad293-65be-4a29-bd9e-60f6c7287f91") }, writeConcern: { w: "majority", wtimeout: 60000 }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1569410841, 1), signature: { hash: BinData(0, 9ED82621A14AC58D61E8AEDEBB8BDF1492223332), keyId: 6740562914618376207 } }, $client: { application: { name: "MongoDB Shell" }, driver: { name: "MongoDB Internal Client", version: "4.0.3" }, os: { type: "Darwin", name: "Mac OS X", architecture: "x86_64", version: "18.7.0" }, mongos: { host: "ShailendraMishra-anmepls-MacBook-Pro.local:21010", client: "127.0.0.1:56588", version: "4.0.3" } }, $configServerState: { opTime: { ts: Timestamp(1569410841, 1), t: 1 } }, $db: "admin" } numYields:0 reslen:501 locks:{ Global: { acquireCount: { r: 7, w: 4 } }, Database: { acquireCount: { r: 3, w: 4 } }, Collection: { acquireCount: { r: 3, w: 2 } }, Metadata: { acquireCount: { W: 1 } }, Mutex: { acquireCount: { r: 1, W: 1 } }, oplog: { acquireCount: { w: 2 } } } protocol:op_msg 296ms
2019-09-25T16:57:25.365+0530 I ASIO     [ShardRegistry] Connecting to localhost:37019
2019-09-25T16:57:25.368+0530 I ASIO     [ShardRegistry] Connecting to localhost:47017
2019-09-25T16:58:14.326+0530 I SHARDING [conn24] distributed lock 'school' acquired for 'enableSharding', ts : 5d8b4f4eec3bf68e0338f71e
2019-09-25T16:58:14.340+0530 I SHARDING [conn24] Registering new database { _id: "school", primary: "shard2", partitioned: false, version: { uuid: UUID("0124c7d7-0fcd-4ae5-9ba6-acadb775253c"), lastMod: 1 } } in sharding catalog
2019-09-25T16:58:14.345+0530 I STORAGE  [conn24] createCollection: config.databases with generated UUID: ba6a2a29-deee-494a-9bbf-dd6dbeff663e
2019-09-25T16:58:14.571+0530 I SHARDING [conn24] Enabling sharding for database [school] in config db
2019-09-25T16:58:14.607+0530 I SHARDING [conn24] distributed lock with ts: 5d8b4f4eec3bf68e0338f71e' unlocked.
2019-09-25T16:58:14.608+0530 I COMMAND  [conn24] command admin.$cmd appName: "MongoDB Shell" command: _configsvrEnableSharding { _configsvrEnableSharding: "school", lsid: { id: UUID("659ad293-65be-4a29-bd9e-60f6c7287f91") }, writeConcern: { w: "majority", wtimeout: 60000 }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1569410884, 1), signature: { hash: BinData(0, 2E3E050E0C271B9D0C8B43A0362C5CFF88925EAF), keyId: 6740562914618376207 } }, $client: { application: { name: "MongoDB Shell" }, driver: { name: "MongoDB Internal Client", version: "4.0.3" }, os: { type: "Darwin", name: "Mac OS X", architecture: "x86_64", version: "18.7.0" }, mongos: { host: "ShailendraMishra-anmepls-MacBook-Pro.local:21010", client: "127.0.0.1:56588", version: "4.0.3" } }, $configServerState: { opTime: { ts: Timestamp(1569410884, 1), t: 1 } }, $db: "admin" } numYields:0 reslen:478 locks:{ Global: { acquireCount: { r: 13, w: 12 } }, Database: { acquireCount: { r: 1, w: 10, W: 1 } }, Collection: { acquireCount: { r: 1, w: 5 } }, oplog: { acquireCount: { w: 5 } } } protocol:op_msg 313ms
2019-09-25T16:58:39.243+0530 I SHARDING [conn24] distributed lock 'school' acquired for 'shardCollection', ts : 5d8b4f67ec3bf68e0338f7bd
2019-09-25T16:58:39.266+0530 I SHARDING [conn24] distributed lock 'school.students' acquired for 'shardCollection', ts : 5d8b4f67ec3bf68e0338f7c6
2019-09-25T16:58:39.269+0530 I NETWORK  [conn24] Successfully connected to shard2/localhost:37017,localhost:37018,localhost:37019 (1 connections now open to shard2/localhost:37017,localhost:37018,localhost:37019 with a 0 second timeout)
2019-09-25T16:58:39.300+0530 I SHARDING [conn24] distributed lock with ts: 5d8b4f67ec3bf68e0338f7c6' unlocked.
2019-09-25T16:58:39.326+0530 I SHARDING [conn24] distributed lock with ts: 5d8b4f67ec3bf68e0338f7bd' unlocked.
2019-09-25T16:58:39.332+0530 I COMMAND  [conn24] command admin.$cmd appName: "MongoDB Shell" command: _configsvrShardCollection { _configsvrShardCollection: "school.students", key: { student_id: 1.0 }, unique: false, numInitialChunks: 0, getUUIDfromPrimaryShard: true, lsid: { id: UUID("659ad293-65be-4a29-bd9e-60f6c7287f91") }, writeConcern: { w: "majority", wtimeout: 60000 }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1569410914, 1), signature: { hash: BinData(0, A28D49A819EA9932A32868A8078653C610DCCA2E), keyId: 6740562914618376207 } }, $client: { application: { name: "MongoDB Shell" }, driver: { name: "MongoDB Internal Client", version: "4.0.3" }, os: { type: "Darwin", name: "Mac OS X", architecture: "x86_64", version: "18.7.0" }, mongos: { host: "ShailendraMishra-anmepls-MacBook-Pro.local:21010", client: "127.0.0.1:56588", version: "4.0.3" } }, $configServerState: { opTime: { ts: Timestamp(1569410914, 1), t: 1 } }, $db: "admin" } numYields:0 ok:0 errMsg:"Cannot accept sharding commands if not started with --shardsvr" errName:NoShardingEnabled errCode:193 reslen:595 locks:{ Global: { acquireCount: { r: 10, w: 8 } }, Database: { acquireCount: { r: 2, w: 8 } }, Collection: { acquireCount: { r: 2, w: 4 } }, Mutex: { acquireCount: { W: 1 } }, oplog: { acquireCount: { w: 4 } } } protocol:op_msg 112ms
2019-09-25T17:01:18.989+0530 I SH_REFR  [ConfigServerCatalogCacheLoader-4] Refresh for collection config.system.sessions took 0 ms and found the collection is not sharded
2019-09-25T17:01:19.020+0530 I SHARDING [LogicalSessionCacheRefresh] distributed lock 'config' acquired for 'shardCollection', ts : 5d8b5006ec3bf68e0338fa73
2019-09-25T17:01:19.047+0530 I SHARDING [LogicalSessionCacheRefresh] distributed lock 'config.system.sessions' acquired for 'shardCollection', ts : 5d8b5007ec3bf68e0338fa7d
2019-09-25T17:01:19.050+0530 I NETWORK  [LogicalSessionCacheRefresh] Starting new replica set monitor for conf/localhost:57040,localhost:57041,localhost:57042
2019-09-25T17:01:19.052+0530 I NETWORK  [LogicalSessionCacheRefresh] Successfully connected to localhost:57041 (1 connections now open to localhost:57041 with a 5 second timeout)
2019-09-25T17:01:19.053+0530 I NETWORK  [ReplicaSetMonitor-TaskExecutor] Successfully connected to localhost:57042 (1 connections now open to localhost:57042 with a 5 second timeout)
2019-09-25T17:01:19.054+0530 I NETWORK  [listener] connection accepted from 127.0.0.1:58030 #45 (9 connections now open)
2019-09-25T17:01:19.055+0530 I NETWORK  [conn45] received client metadata from 127.0.0.1:58030 conn45: { driver: { name: "MongoDB Internal Client", version: "4.0.3" }, os: { type: "Darwin", name: "Mac OS X", architecture: "x86_64", version: "18.7.0" } }
2019-09-25T17:01:19.055+0530 I NETWORK  [LogicalSessionCacheRefresh] Successfully connected to localhost:57040 (1 connections now open to localhost:57040 with a 5 second timeout)
2019-09-25T17:01:19.056+0530 I NETWORK  [LogicalSessionCacheRefresh] Successfully connected to conf/localhost:57040,localhost:57041,localhost:57042 (1 connections now open to conf/localhost:57040,localhost:57041,localhost:57042 with a 0 second timeout)
2019-09-25T17:01:19.056+0530 I NETWORK  [listener] connection accepted from 127.0.0.1:58031 #47 (10 connections now open)
2019-09-25T17:01:19.057+0530 I NETWORK  [conn47] received client metadata from 127.0.0.1:58031 conn47: { driver: { name: "MongoDB Internal Client", version: "4.0.3" }, os: { type: "Darwin", name: "Mac OS X", architecture: "x86_64", version: "18.7.0" } }
2019-09-25T17:01:19.057+0530 I NETWORK  [LogicalSessionCacheRefresh] Successfully connected to shard1/localhost:27017,localhost:27018,localhost:27019 (1 connections now open to shard1/localhost:27017,localhost:27018,localhost:27019 with a 0 second timeout)
2019-09-25T17:01:19.083+0530 I SHARDING [LogicalSessionCacheRefresh] distributed lock with ts: 5d8b5007ec3bf68e0338fa7d' unlocked.
2019-09-25T17:01:19.108+0530 I SHARDING [LogicalSessionCacheRefresh] distributed lock with ts: 5d8b5006ec3bf68e0338fa73' unlocked.
2019-09-25T17:01:19.113+0530 I COMMAND  [LogicalSessionCacheRefresh] command admin.$cmd command: _configsvrShardCollection { _configsvrShardCollection: "config.system.sessions", key: { _id: 1 }, unique: false, numInitialChunks: 0, getUUIDfromPrimaryShard: true, writeConcern: { w: "majority", wtimeout: 60000 }, $db: "admin" } numYields:0 ok:0 errMsg:"Cannot accept sharding commands if not started with --shardsvr" errName:NoShardingEnabled errCode:193 reslen:389 locks:{ Global: { acquireCount: { r: 9, w: 8 } }, Database: { acquireCount: { r: 1, w: 8 } }, Collection: { acquireCount: { r: 1, w: 4 } }, Mutex: { acquireCount: { W: 1 } }, oplog: { acquireCount: { w: 4 } } } protocol:op_msg 119ms
2019-09-25T17:01:19.113+0530 I CONTROL  [LogicalSessionCacheRefresh] Failed to create config.system.sessions: Cannot accept sharding commands if not started with --shardsvr, will try again at the next refresh interval
2019-09-25T17:01:19.113+0530 I CONTROL  [LogicalSessionCacheRefresh] Sessions collection is not set up; waiting until next sessions refresh interval: Cannot accept sharding commands if not started with --shardsvr
2019-09-25T17:02:02.825+0530 I SHARDING [conn24] distributed lock 'school' acquired for 'shardCollection', ts : 5d8b5032ec3bf68e0338fb57
2019-09-25T17:02:02.850+0530 I SHARDING [conn24] distributed lock 'school.students' acquired for 'shardCollection', ts : 5d8b5032ec3bf68e0338fb61
2019-09-25T17:02:02.880+0530 I SHARDING [conn24] distributed lock with ts: 5d8b5032ec3bf68e0338fb61' unlocked.
2019-09-25T17:02:02.903+0530 I SHARDING [conn24] distributed lock with ts: 5d8b5032ec3bf68e0338fb57' unlocked.
2019-09-25T17:02:02.904+0530 I COMMAND  [conn24] command admin.$cmd appName: "MongoDB Shell" command: _configsvrShardCollection { _configsvrShardCollection: "school.students", key: { student_id: 1.0 }, unique: false, numInitialChunks: 0, getUUIDfromPrimaryShard: true, lsid: { id: UUID("659ad293-65be-4a29-bd9e-60f6c7287f91") }, writeConcern: { w: "majority", wtimeout: 60000 }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1569411115, 1), signature: { hash: BinData(0, D3837BCF59FB437AE487DF6131F2CE4D62543DB5), keyId: 6740562914618376207 } }, $client: { application: { name: "MongoDB Shell" }, driver: { name: "MongoDB Internal Client", version: "4.0.3" }, os: { type: "Darwin", name: "Mac OS X", architecture: "x86_64", version: "18.7.0" }, mongos: { host: "ShailendraMishra-anmepls-MacBook-Pro.local:21010", client: "127.0.0.1:56588", version: "4.0.3" } }, $configServerState: { opTime: { ts: Timestamp(1569411115, 1), t: 1 } }, $db: "admin" } numYields:0 ok:0 errMsg:"Cannot accept sharding commands if not started with --shardsvr" errName:NoShardingEnabled errCode:193 reslen:595 locks:{ Global: { acquireCount: { r: 10, w: 8 } }, Database: { acquireCount: { r: 2, w: 8 } }, Collection: { acquireCount: { r: 2, w: 4 } }, Mutex: { acquireCount: { W: 1 } }, oplog: { acquireCount: { w: 4 } } } protocol:op_msg 107ms
2019-09-25T17:02:09.541+0530 I ASIO     [AddShard-TaskExecutor] Dropping all pooled connections to localhost:27017 due to NetworkInterfaceExceededTimeLimit: Connection pool has been idle for longer than the host timeout
2019-09-25T17:02:17.628+0530 I ASIO     [AddShard-TaskExecutor] Dropping all pooled connections to localhost:37019 due to NetworkInterfaceExceededTimeLimit: Connection pool has been idle for longer than the host timeout
2019-09-25T17:02:23.188+0530 I ASIO     [AddShard-TaskExecutor] Dropping all pooled connections to localhost:47017 due to NetworkInterfaceExceededTimeLimit: Connection pool has been idle for longer than the host timeout
2019-09-25T17:03:47.742+0530 I SHARDING [conn24] distributed lock 'school' acquired for 'shardCollection', ts : 5d8b509bec3bf68e0338fd2d
2019-09-25T17:03:47.766+0530 I SHARDING [conn24] distributed lock 'school.students' acquired for 'shardCollection', ts : 5d8b509bec3bf68e0338fd37
2019-09-25T17:03:47.796+0530 I SHARDING [conn24] distributed lock with ts: 5d8b509bec3bf68e0338fd37' unlocked.
2019-09-25T17:03:47.822+0530 I SHARDING [conn24] distributed lock with ts: 5d8b509bec3bf68e0338fd2d' unlocked.
2019-09-25T17:03:47.826+0530 I COMMAND  [conn24] command admin.$cmd appName: "MongoDB Shell" command: _configsvrShardCollection { _configsvrShardCollection: "school.students", key: { student_id: 1.0 }, unique: false, numInitialChunks: 0, getUUIDfromPrimaryShard: true, lsid: { id: UUID("659ad293-65be-4a29-bd9e-60f6c7287f91") }, writeConcern: { w: "majority", wtimeout: 60000 }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1569411226, 1), signature: { hash: BinData(0, F6B2AC52715289301F22D00F1C5F0F7C4168AB23), keyId: 6740562914618376207 } }, $client: { application: { name: "MongoDB Shell" }, driver: { name: "MongoDB Internal Client", version: "4.0.3" }, os: { type: "Darwin", name: "Mac OS X", architecture: "x86_64", version: "18.7.0" }, mongos: { host: "ShailendraMishra-anmepls-MacBook-Pro.local:21010", client: "127.0.0.1:56588", version: "4.0.3" } }, $configServerState: { opTime: { ts: Timestamp(1569411226, 1), t: 1 } }, $db: "admin" } numYields:0 ok:0 errMsg:"Cannot accept sharding commands if not started with --shardsvr" errName:NoShardingEnabled errCode:193 reslen:595 locks:{ Global: { acquireCount: { r: 10, w: 8 } }, Database: { acquireCount: { r: 2, w: 8 } }, Collection: { acquireCount: { r: 2, w: 4 } }, Mutex: { acquireCount: { W: 1 } }, oplog: { acquireCount: { w: 4 } } } protocol:op_msg 111ms
2019-09-25T17:05:08.390+0530 I SHARDING [conn24] distributed lock 'school' acquired for 'shardCollection', ts : 5d8b50ecec3bf68e0338fea0
2019-09-25T17:05:08.416+0530 I SHARDING [conn24] distributed lock 'school.students' acquired for 'shardCollection', ts : 5d8b50ecec3bf68e0338fea9
2019-09-25T17:05:08.442+0530 I SHARDING [conn24] distributed lock with ts: 5d8b50ecec3bf68e0338fea9' unlocked.
2019-09-25T17:05:08.471+0530 I SHARDING [conn24] distributed lock with ts: 5d8b50ecec3bf68e0338fea0' unlocked.
2019-09-25T17:05:08.475+0530 I COMMAND  [conn24] command admin.$cmd appName: "MongoDB Shell" command: _configsvrShardCollection { _configsvrShardCollection: "school.students", key: { student_id: 1.0 }, unique: false, numInitialChunks: 0, getUUIDfromPrimaryShard: true, lsid: { id: UUID("659ad293-65be-4a29-bd9e-60f6c7287f91") }, writeConcern: { w: "majority", wtimeout: 60000 }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1569411306, 1), signature: { hash: BinData(0, F0F3720147B0B665CDE7A48381A3E52068C90A78), keyId: 6740562914618376207 } }, $client: { application: { name: "MongoDB Shell" }, driver: { name: "MongoDB Internal Client", version: "4.0.3" }, os: { type: "Darwin", name: "Mac OS X", architecture: "x86_64", version: "18.7.0" }, mongos: { host: "ShailendraMishra-anmepls-MacBook-Pro.local:21010", client: "127.0.0.1:56588", version: "4.0.3" } }, $configServerState: { opTime: { ts: Timestamp(1569411306, 1), t: 1 } }, $db: "admin" } numYields:0 ok:0 errMsg:"Cannot accept sharding commands if not started with --shardsvr" errName:NoShardingEnabled errCode:193 reslen:595 locks:{ Global: { acquireCount: { r: 10, w: 8 } }, Database: { acquireCount: { r: 2, w: 8 } }, Collection: { acquireCount: { r: 2, w: 4 } }, Mutex: { acquireCount: { W: 1 } }, oplog: { acquireCount: { w: 4 } } } protocol:op_msg 113ms
2019-09-25T17:06:18.995+0530 I SH_REFR  [ConfigServerCatalogCacheLoader-5] Refresh for collection config.system.sessions took 0 ms and found the collection is not sharded
2019-09-25T17:06:19.028+0530 I SHARDING [LogicalSessionCacheRefresh] distributed lock 'config' acquired for 'shardCollection', ts : 5d8b5132ec3bf68e0338ffe1
2019-09-25T17:06:19.055+0530 I SHARDING [LogicalSessionCacheRefresh] distributed lock 'config.system.sessions' acquired for 'shardCollection', ts : 5d8b5133ec3bf68e0338ffeb
2019-09-25T17:06:19.079+0530 I SHARDING [LogicalSessionCacheRefresh] distributed lock with ts: 5d8b5133ec3bf68e0338ffeb' unlocked.
2019-09-25T17:06:19.104+0530 I SHARDING [LogicalSessionCacheRefresh] distributed lock with ts: 5d8b5132ec3bf68e0338ffe1' unlocked.
2019-09-25T17:06:19.108+0530 I COMMAND  [LogicalSessionCacheRefresh] command admin.$cmd command: _configsvrShardCollection { _configsvrShardCollection: "config.system.sessions", key: { _id: 1 }, unique: false, numInitialChunks: 0, getUUIDfromPrimaryShard: true, writeConcern: { w: "majority", wtimeout: 60000 }, $db: "admin" } numYields:0 ok:0 errMsg:"Cannot accept sharding commands if not started with --shardsvr" errName:NoShardingEnabled errCode:193 reslen:389 locks:{ Global: { acquireCount: { r: 9, w: 8 } }, Database: { acquireCount: { r: 1, w: 8 } }, Collection: { acquireCount: { r: 1, w: 4 } }, Mutex: { acquireCount: { W: 1 } }, oplog: { acquireCount: { w: 4 } } } protocol:op_msg 109ms
2019-09-25T17:06:19.109+0530 I CONTROL  [LogicalSessionCacheRefresh] Failed to create config.system.sessions: Cannot accept sharding commands if not started with --shardsvr, will try again at the next refresh interval
2019-09-25T17:06:19.109+0530 I CONTROL  [LogicalSessionCacheRefresh] Sessions collection is not set up; waiting until next sessions refresh interval: Cannot accept sharding commands if not started with --shardsvr
2019-09-25T17:07:57.526+0530 I SHARDING [conn24] distributed lock 'school' acquired for 'shardCollection', ts : 5d8b5195ec3bf68e033901a7
2019-09-25T17:07:57.553+0530 I SHARDING [conn24] distributed lock 'school.students' acquired for 'shardCollection', ts : 5d8b5195ec3bf68e033901b1
2019-09-25T17:07:57.580+0530 I SHARDING [conn24] distributed lock with ts: 5d8b5195ec3bf68e033901b1' unlocked.
2019-09-25T17:07:57.609+0530 I SHARDING [conn24] distributed lock with ts: 5d8b5195ec3bf68e033901a7' unlocked.
2019-09-25T17:07:57.613+0530 I COMMAND  [conn24] command admin.$cmd appName: "MongoDB Shell" command: _configsvrShardCollection { _configsvrShardCollection: "school.students", key: { student_id: 1.0 }, unique: false, numInitialChunks: 0, getUUIDfromPrimaryShard: true, lsid: { id: UUID("659ad293-65be-4a29-bd9e-60f6c7287f91") }, writeConcern: { w: "majority", wtimeout: 60000 }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1569411477, 1), signature: { hash: BinData(0, A8C614EB6CFC30E36CCCAD84D609002906FACA36), keyId: 6740562914618376207 } }, $client: { application: { name: "MongoDB Shell" }, driver: { name: "MongoDB Internal Client", version: "4.0.3" }, os: { type: "Darwin", name: "Mac OS X", architecture: "x86_64", version: "18.7.0" }, mongos: { host: "ShailendraMishra-anmepls-MacBook-Pro.local:21010", client: "127.0.0.1:56588", version: "4.0.3" } }, $configServerState: { opTime: { ts: Timestamp(1569411477, 1), t: 1 } }, $db: "admin" } numYields:0 ok:0 errMsg:"Cannot accept sharding commands if not started with --shardsvr" errName:NoShardingEnabled errCode:193 reslen:595 locks:{ Global: { acquireCount: { r: 10, w: 8 } }, Database: { acquireCount: { r: 2, w: 8 } }, Collection: { acquireCount: { r: 2, w: 4 } }, Mutex: { acquireCount: { W: 1 } }, oplog: { acquireCount: { w: 4 } } } protocol:op_msg 112ms
2019-09-25T17:08:40.705+0530 I SHARDING [conn24] distributed lock 'school' acquired for 'shardCollection', ts : 5d8b51c0ec3bf68e0339026c
2019-09-25T17:08:40.731+0530 I SHARDING [conn24] distributed lock 'school.students' acquired for 'shardCollection', ts : 5d8b51c0ec3bf68e03390276
2019-09-25T17:08:40.760+0530 I SHARDING [conn24] distributed lock with ts: 5d8b51c0ec3bf68e03390276' unlocked.
2019-09-25T17:08:40.786+0530 I SHARDING [conn24] distributed lock with ts: 5d8b51c0ec3bf68e0339026c' unlocked.
2019-09-25T17:08:40.787+0530 I COMMAND  [conn24] command admin.$cmd appName: "MongoDB Shell" command: _configsvrShardCollection { _configsvrShardCollection: "school.students", key: { student_id: 1.0 }, unique: false, numInitialChunks: 0, getUUIDfromPrimaryShard: true, lsid: { id: UUID("659ad293-65be-4a29-bd9e-60f6c7287f91") }, writeConcern: { w: "majority", wtimeout: 60000 }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1569411517, 1), signature: { hash: BinData(0, 1519D6ECC72E35620FD39A92F98938731CE6CD83), keyId: 6740562914618376207 } }, $client: { application: { name: "MongoDB Shell" }, driver: { name: "MongoDB Internal Client", version: "4.0.3" }, os: { type: "Darwin", name: "Mac OS X", architecture: "x86_64", version: "18.7.0" }, mongos: { host: "ShailendraMishra-anmepls-MacBook-Pro.local:21010", client: "127.0.0.1:56588", version: "4.0.3" } }, $configServerState: { opTime: { ts: Timestamp(1569411517, 1), t: 1 } }, $db: "admin" } numYields:0 ok:0 errMsg:"Cannot accept sharding commands if not started with --shardsvr" errName:NoShardingEnabled errCode:193 reslen:595 locks:{ Global: { acquireCount: { r: 10, w: 8 } }, Database: { acquireCount: { r: 2, w: 8 } }, Collection: { acquireCount: { r: 2, w: 4 } }, Mutex: { acquireCount: { W: 1 } }, oplog: { acquireCount: { w: 4 } } } protocol:op_msg 110ms
2019-09-25T17:10:03.979+0530 I NETWORK  [listener] connection accepted from 127.0.0.1:60218 #49 (11 connections now open)
2019-09-25T17:10:03.980+0530 I NETWORK  [conn49] received client metadata from 127.0.0.1:60218 conn49: { driver: { name: "NetworkInterfaceTL", version: "4.0.3" }, os: { type: "Darwin", name: "Mac OS X", architecture: "x86_64", version: "18.7.0" } }
2019-09-25T17:11:18.999+0530 I SH_REFR  [ConfigServerCatalogCacheLoader-6] Refresh for collection config.system.sessions took 0 ms and found the collection is not sharded
2019-09-25T17:11:19.032+0530 I SHARDING [LogicalSessionCacheRefresh] distributed lock 'config' acquired for 'shardCollection', ts : 5d8b525fec3bf68e0339053a
2019-09-25T17:11:19.058+0530 I SHARDING [LogicalSessionCacheRefresh] distributed lock 'config.system.sessions' acquired for 'shardCollection', ts : 5d8b525fec3bf68e03390545
2019-09-25T17:11:19.086+0530 I SHARDING [LogicalSessionCacheRefresh] distributed lock with ts: 5d8b525fec3bf68e03390545' unlocked.
2019-09-25T17:11:19.117+0530 I SHARDING [LogicalSessionCacheRefresh] distributed lock with ts: 5d8b525fec3bf68e0339053a' unlocked.
2019-09-25T17:11:19.121+0530 I COMMAND  [LogicalSessionCacheRefresh] command admin.$cmd command: _configsvrShardCollection { _configsvrShardCollection: "config.system.sessions", key: { _id: 1 }, unique: false, numInitialChunks: 0, getUUIDfromPrimaryShard: true, writeConcern: { w: "majority", wtimeout: 60000 }, $db: "admin" } numYields:0 ok:0 errMsg:"Cannot accept sharding commands if not started with --shardsvr" errName:NoShardingEnabled errCode:193 reslen:389 locks:{ Global: { acquireCount: { r: 9, w: 8 } }, Database: { acquireCount: { r: 1, w: 8 } }, Collection: { acquireCount: { r: 1, w: 4 } }, Mutex: { acquireCount: { W: 1 } }, oplog: { acquireCount: { w: 4 } } } protocol:op_msg 109ms
2019-09-25T17:11:19.121+0530 I CONTROL  [LogicalSessionCacheRefresh] Failed to create config.system.sessions: Cannot accept sharding commands if not started with --shardsvr, will try again at the next refresh interval
2019-09-25T17:11:19.122+0530 I CONTROL  [LogicalSessionCacheRefresh] Sessions collection is not set up; waiting until next sessions refresh interval: Cannot accept sharding commands if not started with --shardsvr
2019-09-25T17:12:19.661+0530 I SHARDING [conn24] distributed lock 'school' acquired for 'enableSharding', ts : 5d8b529bec3bf68e03390666
2019-09-25T17:12:19.669+0530 I SHARDING [conn24] Enabling sharding for database [school] in config db
2019-09-25T17:12:19.694+0530 I SHARDING [conn24] distributed lock with ts: 5d8b529bec3bf68e03390666' unlocked.
2019-09-25T17:12:29.817+0530 I SHARDING [conn24] distributed lock 'school' acquired for 'shardCollection', ts : 5d8b52a5ec3bf68e033906af
2019-09-25T17:12:29.841+0530 I SHARDING [conn24] distributed lock 'school.students' acquired for 'shardCollection', ts : 5d8b52a5ec3bf68e033906b8
2019-09-25T17:12:29.866+0530 I SHARDING [conn24] distributed lock with ts: 5d8b52a5ec3bf68e033906b8' unlocked.
2019-09-25T17:12:29.892+0530 I SHARDING [conn24] distributed lock with ts: 5d8b52a5ec3bf68e033906af' unlocked.
2019-09-25T17:12:29.896+0530 I COMMAND  [conn24] command admin.$cmd appName: "MongoDB Shell" command: _configsvrShardCollection { _configsvrShardCollection: "school.students", key: { student_id: 1.0 }, unique: false, numInitialChunks: 0, getUUIDfromPrimaryShard: true, lsid: { id: UUID("659ad293-65be-4a29-bd9e-60f6c7287f91") }, writeConcern: { w: "majority", wtimeout: 60000 }, $replData: 1, $clusterTime: { clusterTime: Timestamp(1569411748, 1), signature: { hash: BinData(0, 0BAC75DC41342466ADA66E27C0257685CF79DFFA), keyId: 6740562914618376207 } }, $client: { application: { name: "MongoDB Shell" }, driver: { name: "MongoDB Internal Client", version: "4.0.3" }, os: { type: "Darwin", name: "Mac OS X", architecture: "x86_64", version: "18.7.0" }, mongos: { host: "ShailendraMishra-anmepls-MacBook-Pro.local:21010", client: "127.0.0.1:56588", version: "4.0.3" } }, $configServerState: { opTime: { ts: Timestamp(1569411748, 1), t: 1 } }, $db: "admin" } numYields:0 ok:0 errMsg:"Cannot accept sharding commands if not started with --shardsvr" errName:NoShardingEnabled errCode:193 reslen:595 locks:{ Global: { acquireCount: { r: 10, w: 8 } }, Database: { acquireCount: { r: 2, w: 8 } }, Collection: { acquireCount: { r: 2, w: 4 } }, Mutex: { acquireCount: { W: 1 } }, oplog: { acquireCount: { w: 4 } } } protocol:op_msg 105ms
2019-09-25T17:15:04.035+0530 I NETWORK  [conn49] end connection 127.0.0.1:60218 (10 connections now open)
2019-09-25T17:16:19.014+0530 I SH_REFR  [ConfigServerCatalogCacheLoader-7] Refresh for collection config.system.sessions took 0 ms and found the collection is not sharded
2019-09-25T17:16:19.042+0530 I SHARDING [LogicalSessionCacheRefresh] distributed lock 'config' acquired for 'shardCollection', ts : 5d8b538bec3bf68e03390a87
2019-09-25T17:16:19.078+0530 I SHARDING [LogicalSessionCacheRefresh] distributed lock 'config.system.sessions' acquired for 'shardCollection', ts : 5d8b538bec3bf68e03390a90
2019-09-25T17:16:19.106+0530 I SHARDING [LogicalSessionCacheRefresh] distributed lock with ts: 5d8b538bec3bf68e03390a90' unlocked.
2019-09-25T17:16:19.133+0530 I SHARDING [LogicalSessionCacheRefresh] distributed lock with ts: 5d8b538bec3bf68e03390a87' unlocked.
2019-09-25T17:16:19.134+0530 I COMMAND  [LogicalSessionCacheRefresh] command admin.$cmd command: _configsvrShardCollection { _configsvrShardCollection: "config.system.sessions", key: { _id: 1 }, unique: false, numInitialChunks: 0, getUUIDfromPrimaryShard: true, writeConcern: { w: "majority", wtimeout: 60000 }, $db: "admin" } numYields:0 ok:0 errMsg:"Cannot accept sharding commands if not started with --shardsvr" errName:NoShardingEnabled errCode:193 reslen:389 locks:{ Global: { acquireCount: { r: 9, w: 8 } }, Database: { acquireCount: { r: 1, w: 8 } }, Collection: { acquireCount: { r: 1, w: 4 } }, Mutex: { acquireCount: { W: 1 } }, oplog: { acquireCount: { w: 4 } } } protocol:op_msg 113ms
2019-09-25T17:16:19.136+0530 I CONTROL  [LogicalSessionCacheRefresh] Failed to create config.system.sessions: Cannot accept sharding commands if not started with --shardsvr, will try again at the next refresh interval
2019-09-25T17:16:19.147+0530 I CONTROL  [LogicalSessionCacheRefresh] Sessions collection is not set up; waiting until next sessions refresh interval: Cannot accept sharding commands if not started with --shardsvr
2019-09-25T17:21:19.024+0530 I SH_REFR  [ConfigServerCatalogCacheLoader-8] Refresh for collection config.system.sessions took 0 ms and found the collection is not sharded
2019-09-25T17:21:19.054+0530 I SHARDING [LogicalSessionCacheRefresh] distributed lock 'config' acquired for 'shardCollection', ts : 5d8b54b7ec3bf68e03390f99
2019-09-25T17:21:19.080+0530 I SHARDING [LogicalSessionCacheRefresh] distributed lock 'config.system.sessions' acquired for 'shardCollection', ts : 5d8b54b7ec3bf68e03390fa3
2019-09-25T17:21:19.118+0530 I SHARDING [LogicalSessionCacheRefresh] distributed lock with ts: 5d8b54b7ec3bf68e03390fa3' unlocked.
2019-09-25T17:21:19.180+0530 I SHARDING [LogicalSessionCacheRefresh] distributed lock with ts: 5d8b54b7ec3bf68e03390f99' unlocked.
2019-09-25T17:21:19.182+0530 I COMMAND  [LogicalSessionCacheRefresh] command admin.$cmd command: _configsvrShardCollection { _configsvrShardCollection: "config.system.sessions", key: { _id: 1 }, unique: false, numInitialChunks: 0, getUUIDfromPrimaryShard: true, writeConcern: { w: "majority", wtimeout: 60000 }, $db: "admin" } numYields:0 ok:0 errMsg:"Cannot accept sharding commands if not started with --shardsvr" errName:NoShardingEnabled errCode:193 reslen:389 locks:{ Global: { acquireCount: { r: 9, w: 8 } }, Database: { acquireCount: { r: 1, w: 8 } }, Collection: { acquireCount: { r: 1, w: 4 } }, Mutex: { acquireCount: { W: 1 } }, oplog: { acquireCount: { w: 4 } } } protocol:op_msg 151ms
2019-09-25T17:21:19.195+0530 I CONTROL  [LogicalSessionCacheRefresh] Failed to create config.system.sessions: Cannot accept sharding commands if not started with --shardsvr, will try again at the next refresh interval
2019-09-25T17:21:19.207+0530 I CONTROL  [LogicalSessionCacheRefresh] Sessions collection is not set up; waiting until next sessions refresh interval: Cannot accept sharding commands if not started with --shardsvr
2019-09-25T17:25:52.036+0530 I NETWORK  [listener] connection accepted from 127.0.0.1:64119 #50 (11 connections now open)
2019-09-25T17:25:52.049+0530 I NETWORK  [conn50] received client metadata from 127.0.0.1:64119 conn50: { driver: { name: "NetworkInterfaceTL", version: "4.0.3" }, os: { type: "Darwin", name: "Mac OS X", architecture: "x86_64", version: "18.7.0" } }
2019-09-25T17:26:19.028+0530 I SH_REFR  [ConfigServerCatalogCacheLoader-9] Refresh for collection config.system.sessions took 0 ms and found the collection is not sharded
2019-09-25T17:26:19.068+0530 I SHARDING [LogicalSessionCacheRefresh] distributed lock 'config' acquired for 'shardCollection', ts : 5d8b55e3ec3bf68e033914a9
2019-09-25T17:26:19.095+0530 I SHARDING [LogicalSessionCacheRefresh] distributed lock 'config.system.sessions' acquired for 'shardCollection', ts : 5d8b55e3ec3bf68e033914b3
2019-09-25T17:26:19.124+0530 I SHARDING [LogicalSessionCacheRefresh] distributed lock with ts: 5d8b55e3ec3bf68e033914b3' unlocked.
2019-09-25T17:26:19.150+0530 I SHARDING [LogicalSessionCacheRefresh] distributed lock with ts: 5d8b55e3ec3bf68e033914a9' unlocked.
2019-09-25T17:26:19.154+0530 I COMMAND  [LogicalSessionCacheRefresh] command admin.$cmd command: _configsvrShardCollection { _configsvrShardCollection: "config.system.sessions", key: { _id: 1 }, unique: false, numInitialChunks: 0, getUUIDfromPrimaryShard: true, writeConcern: { w: "majority", wtimeout: 60000 }, $db: "admin" } numYields:0 ok:0 errMsg:"Cannot accept sharding commands if not started with --shardsvr" errName:NoShardingEnabled errCode:193 reslen:389 locks:{ Global: { acquireCount: { r: 9, w: 8 } }, Database: { acquireCount: { r: 1, w: 8 } }, Collection: { acquireCount: { r: 1, w: 4 } }, Mutex: { acquireCount: { W: 1 } }, oplog: { acquireCount: { w: 4 } } } protocol:op_msg 117ms
2019-09-25T17:26:19.155+0530 I CONTROL  [LogicalSessionCacheRefresh] Failed to create config.system.sessions: Cannot accept sharding commands if not started with --shardsvr, will try again at the next refresh interval
2019-09-25T17:26:19.155+0530 I CONTROL  [LogicalSessionCacheRefresh] Sessions collection is not set up; waiting until next sessions refresh interval: Cannot accept sharding commands if not started with --shardsvr
2019-09-25T17:26:52.063+0530 I NETWORK  [conn24] end connection 127.0.0.1:56217 (10 connections now open)
2019-09-25T17:26:53.945+0530 I NETWORK  [listener] connection accepted from 127.0.0.1:64380 #51 (11 connections now open)
2019-09-25T17:26:53.954+0530 I NETWORK  [conn51] received client metadata from 127.0.0.1:64380 conn51: { driver: { name: "NetworkInterfaceTL", version: "4.0.3" }, os: { type: "Darwin", name: "Mac OS X", architecture: "x86_64", version: "18.7.0" } }
2019-09-25T17:27:53.950+0530 I NETWORK  [conn50] end connection 127.0.0.1:64119 (10 connections now open)
2019-09-25T17:28:14.831+0530 I NETWORK  [conn51] end connection 127.0.0.1:64380 (9 connections now open)
2019-09-25T17:28:14.836+0530 I NETWORK  [conn23] end connection 127.0.0.1:56212 (8 connections now open)
2019-09-25T17:28:17.597+0530 I ASIO     [ShardRegistry] dropping unhealthy pooled connection to localhost:27017
2019-09-25T17:28:17.603+0530 I ASIO     [ShardRegistry] after drop, pool was empty, going to spawn some connections
2019-09-25T17:28:17.603+0530 I ASIO     [ShardRegistry] Connecting to localhost:27017
2019-09-25T17:28:17.604+0530 I ASIO     [ShardRegistry] Failed to connect to localhost:27017 - HostUnreachable: Error connecting to localhost:27017 (127.0.0.1:27017) :: caused by :: Connection refused
2019-09-25T17:28:17.605+0530 I ASIO     [ShardRegistry] Dropping all pooled connections to localhost:27017 due to HostUnreachable: Error connecting to localhost:27017 (127.0.0.1:27017) :: caused by :: Connection refused
2019-09-25T17:28:17.605+0530 I NETWORK  [ShardRegistry] Marking host localhost:27017 as failed :: caused by :: HostUnreachable: Error connecting to localhost:27017 (127.0.0.1:27017) :: caused by :: Connection refused
2019-09-25T17:28:17.607+0530 I NETWORK  [Balancer] Marking host localhost:27018 as failed :: caused by :: Location40356: connection pool: connect failed localhost:27018 : couldn't connect to server localhost:27018, connection attempt failed: SocketException: Error connecting to localhost:27018 (127.0.0.1:27018) :: caused by :: Connection refused
2019-09-25T17:28:17.607+0530 I NETWORK  [Balancer] Marking host localhost:27019 as failed :: caused by :: Location40356: connection pool: connect failed localhost:27019 : couldn't connect to server localhost:27019, connection attempt failed: SocketException: Error connecting to localhost:27019 (127.0.0.1:27019) :: caused by :: Connection refused
2019-09-25T17:28:17.608+0530 W NETWORK  [Balancer] Unable to reach primary for set shard1
2019-09-25T17:28:17.608+0530 I NETWORK  [Balancer] Cannot reach any nodes for set shard1. Please check network connectivity and the status of the set. This has happened for 1 checks in a row.
2019-09-25T17:28:17.710+0530 I NETWORK  [ReplicaSetMonitor-TaskExecutor] Marking host localhost:37019 as failed :: caused by :: Location40356: connection pool: connect failed localhost:37019 : couldn't connect to server localhost:37019, connection attempt failed: SocketException: Error connecting to localhost:37019 (127.0.0.1:37019) :: caused by :: Connection refused
2019-09-25T17:28:17.712+0530 I NETWORK  [ReplicaSetMonitor-TaskExecutor] Marking host localhost:37018 as failed :: caused by :: Location40356: connection pool: connect failed localhost:37018 : couldn't connect to server localhost:37018, connection attempt failed: SocketException: Error connecting to localhost:37018 (127.0.0.1:37018) :: caused by :: Connection refused
2019-09-25T17:28:17.713+0530 I NETWORK  [ReplicaSetMonitor-TaskExecutor] Marking host localhost:37017 as failed :: caused by :: Location40356: connection pool: connect failed localhost:37017 : couldn't connect to server localhost:37017, connection attempt failed: SocketException: Error connecting to localhost:37017 (127.0.0.1:37017) :: caused by :: Connection refused
2019-09-25T17:28:17.714+0530 W NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set shard2
2019-09-25T17:28:17.714+0530 I NETWORK  [ReplicaSetMonitor-TaskExecutor] Cannot reach any nodes for set shard2. Please check network connectivity and the status of the set. This has happened for 1 checks in a row.
2019-09-25T17:28:18.118+0530 W NETWORK  [Balancer] Unable to reach primary for set shard1
2019-09-25T17:28:18.119+0530 I NETWORK  [Balancer] Cannot reach any nodes for set shard1. Please check network connectivity and the status of the set. This has happened for 2 checks in a row.
2019-09-25T17:28:18.626+0530 W NETWORK  [Balancer] Unable to reach primary for set shard1
2019-09-25T17:28:18.626+0530 I NETWORK  [Balancer] Cannot reach any nodes for set shard1. Please check network connectivity and the status of the set. This has happened for 3 checks in a row.
2019-09-25T17:28:19.129+0530 W NETWORK  [Balancer] Unable to reach primary for set shard1
2019-09-25T17:28:19.130+0530 I NETWORK  [Balancer] Cannot reach any nodes for set shard1. Please check network connectivity and the status of the set. This has happened for 4 checks in a row.
2019-09-25T17:28:19.637+0530 W NETWORK  [Balancer] Unable to reach primary for set shard1
2019-09-25T17:28:19.638+0530 I NETWORK  [Balancer] Cannot reach any nodes for set shard1. Please check network connectivity and the status of the set. This has happened for 5 checks in a row.
2019-09-25T17:28:20.145+0530 W NETWORK  [Balancer] Unable to reach primary for set shard1
2019-09-25T17:28:20.145+0530 I NETWORK  [Balancer] Cannot reach any nodes for set shard1. Please check network connectivity and the status of the set. This has happened for 6 checks in a row.
2019-09-25T17:28:20.653+0530 W NETWORK  [Balancer] Unable to reach primary for set shard1
2019-09-25T17:28:20.654+0530 I NETWORK  [Balancer] Cannot reach any nodes for set shard1. Please check network connectivity and the status of the set. This has happened for 7 checks in a row.
2019-09-25T17:28:21.162+0530 W NETWORK  [Balancer] Unable to reach primary for set shard1
2019-09-25T17:28:21.162+0530 I NETWORK  [Balancer] Cannot reach any nodes for set shard1. Please check network connectivity and the status of the set. This has happened for 8 checks in a row.
2019-09-25T17:28:21.665+0530 W NETWORK  [Balancer] Unable to reach primary for set shard1
2019-09-25T17:28:21.666+0530 I NETWORK  [Balancer] Cannot reach any nodes for set shard1. Please check network connectivity and the status of the set. This has happened for 9 checks in a row.
2019-09-25T17:28:22.174+0530 W NETWORK  [Balancer] Unable to reach primary for set shard1
2019-09-25T17:28:22.175+0530 I NETWORK  [Balancer] Cannot reach any nodes for set shard1. Please check network connectivity and the status of the set. This has happened for 10 checks in a row.
2019-09-25T17:28:22.684+0530 W NETWORK  [Balancer] Unable to reach primary for set shard1
2019-09-25T17:28:22.694+0530 I NETWORK  [Balancer] Cannot reach any nodes for set shard1. Please check network connectivity and the status of the set. This has happened for 11 checks in a row.
2019-09-25T17:28:23.199+0530 W NETWORK  [Balancer] Unable to reach primary for set shard1
2019-09-25T17:28:23.221+0530 I NETWORK  [ReplicaSetMonitor-TaskExecutor] Marking host localhost:47017 as failed :: caused by :: Location40356: connection pool: connect failed localhost:47017 : couldn't connect to server localhost:47017, connection attempt failed: SocketException: Error connecting to localhost:47017 (127.0.0.1:47017) :: caused by :: Connection refused
2019-09-25T17:28:23.222+0530 I NETWORK  [ReplicaSetMonitor-TaskExecutor] Marking host localhost:47018 as failed :: caused by :: Location40356: connection pool: connect failed localhost:47018 : couldn't connect to server localhost:47018, connection attempt failed: SocketException: Error connecting to localhost:47018 (127.0.0.1:47018) :: caused by :: Connection refused
2019-09-25T17:28:23.223+0530 I NETWORK  [ReplicaSetMonitor-TaskExecutor] Marking host localhost:47019 as failed :: caused by :: Location40356: connection pool: connect failed localhost:47019 : couldn't connect to server localhost:47019, connection attempt failed: SocketException: Error connecting to localhost:47019 (127.0.0.1:47019) :: caused by :: Connection refused
2019-09-25T17:28:23.224+0530 W NETWORK  [ReplicaSetMonitor-TaskExecutor] Unable to reach primary for set shard3
2019-09-25T17:28:23.224+0530 I NETWORK  [ReplicaSetMonitor-TaskExecutor] Cannot reach any nodes for set shard3. Please check network connectivity and the status of the set. This has happened for 1 checks in a row.
2019-09-25T17:28:23.708+0530 W NETWORK  [Balancer] Unable to reach primary for set shard1
2019-09-25T17:28:24.216+0530 W NETWORK  [Balancer] Unable to reach primary for set shard1
2019-09-25T17:28:24.722+0530 W NETWORK  [Balancer] Unable to reach primary for set shard1
2019-09-25T17:28:24.821+0530 I NETWORK  [conn11] end connection 127.0.0.1:51808 (7 connections now open)
2019-09-25T17:28:24.821+0530 I NETWORK  [conn7] end connection 127.0.0.1:51787 (6 connections now open)
2019-09-25T17:28:25.001+0530 E STORAGE  [ftdc] WiredTiger error (2) [1569412705:1757][8646:0x700008df2000], WT_SESSION.open_cursor: __posix_fs_size, 311: /data/config/config-a/collection-8-2912480934098975287.wt: file-size: stat: No such file or directory Raw: [1569412705:1757][8646:0x700008df2000], WT_SESSION.open_cursor: __posix_fs_size, 311: /data/config/config-a/collection-8-2912480934098975287.wt: file-size: stat: No such file or directory
2019-09-25T17:28:25.228+0530 W NETWORK  [Balancer] Unable to reach primary for set shard1
2019-09-25T17:28:25.726+0530 E STORAGE  [thread26] WiredTiger error (2) [1569412705:726295][8646:0x7000088d4000], log-server: __directory_list_worker, 48: /data/config/config-a/journal: directory-list: opendir: No such file or directory Raw: [1569412705:726295][8646:0x7000088d4000], log-server: __directory_list_worker, 48: /data/config/config-a/journal: directory-list: opendir: No such file or directory
2019-09-25T17:28:25.727+0530 E STORAGE  [thread26] WiredTiger error (2) [1569412705:727577][8646:0x7000088d4000], log-server: __log_prealloc_once, 469: log pre-alloc server error: No such file or directory Raw: [1569412705:727577][8646:0x7000088d4000], log-server: __log_prealloc_once, 469: log pre-alloc server error: No such file or directory
2019-09-25T17:28:25.728+0530 E STORAGE  [thread26] WiredTiger error (2) [1569412705:728297][8646:0x7000088d4000], log-server: __log_server, 1015: log server error: No such file or directory Raw: [1569412705:728297][8646:0x7000088d4000], log-server: __log_server, 1015: log server error: No such file or directory
2019-09-25T17:28:25.728+0530 E STORAGE  [thread26] WiredTiger error (-31804) [1569412705:728760][8646:0x7000088d4000], log-server: __wt_panic, 523: the process must exit and restart: WT_PANIC: WiredTiger library panic Raw: [1569412705:728760][8646:0x7000088d4000], log-server: __wt_panic, 523: the process must exit and restart: WT_PANIC: WiredTiger library panic
2019-09-25T17:28:25.729+0530 F -        [thread26] Fatal Assertion 50853 at src/mongo/db/storage/wiredtiger/wiredtiger_util.cpp 408
2019-09-25T17:28:25.729+0530 F -        [thread26] 

***aborting after fassert() failure


2019-09-25T17:28:25.731+0530 W NETWORK  [Balancer] Unable to reach primary for set shard1
2019-09-25T17:28:25.734+0530 F -        [thread26] Got signal: 6 (Abort trap: 6).
 0x1055de359 0x1055ddc1d 0x7fff77092b5d 0x0 0x7fff76f4c6a6 0x1055d436b 0x103e19905 0x103f24905 0x103f2434c 0x103f2528e 0x103e7fbbd 0x7fff7709b2eb 0x7fff7709e249 0x7fff7709a40d
----- BEGIN BACKTRACE -----
{"backtrace":[{"b":"103D8C000","o":"1852359","s":"_ZN5mongo15printStackTraceERNSt3__113basic_ostreamIcNS0_11char_traitsIcEEEE"},{"b":"103D8C000","o":"1851C1D","s":"_ZN5mongo12_GLOBAL__N_110abruptQuitEi"},{"b":"7FFF7708E000","o":"4B5D","s":"_sigtramp"},{"b":"0","o":"0"},{"b":"7FFF76EF1000","o":"5B6A6","s":"abort"},{"b":"103D8C000","o":"184836B","s":"_ZN5mongo25fassertFailedWithLocationEiPKcj"},{"b":"103D8C000","o":"8D905","s":"_ZN5mongo12_GLOBAL__N_141mdb_handle_error_with_startup_suppressionEP18__wt_event_handlerP12__wt_sessioniPKc"},{"b":"103D8C000","o":"198905","s":"__eventv"},{"b":"103D8C000","o":"19834C","s":"__wt_err_func"},{"b":"103D8C000","o":"19928E","s":"__wt_panic"},{"b":"103D8C000","o":"F3BBD","s":"__log_server"},{"b":"7FFF77098000","o":"32EB","s":"_pthread_body"},{"b":"7FFF77098000","o":"6249","s":"_pthread_start"},{"b":"7FFF77098000","o":"240D","s":"thread_start"}],"processInfo":{ "mongodbVersion" : "4.0.3", "gitVersion" : "7ea530946fa7880364d88c8d8b6026bbc9ffa48c", "compiledModules" : [], "uname" : { "sysname" : "Darwin", "release" : "18.7.0", "version" : "Darwin Kernel Version 18.7.0: Tue Aug 20 16:57:14 PDT 2019; root:xnu-4903.271.2~2/RELEASE_X86_64", "machine" : "x86_64" }, "somap" : [ { "path" : "/usr/local/bin/mongod", "machType" : 2, "b" : "103D8C000", "vmaddr" : "100000000", "buildId" : "393A2E83DB463F878EB6A384DAA13B9B" }, { "path" : "/usr/lib/libcurl.4.dylib", "machType" : 6, "b" : "7FFF7491D000", "vmaddr" : "7FFF55380000", "buildId" : "CC3D005ECD2F3345A8B3B8A3050B284B" }, { "path" : "/usr/lib/libresolv.9.dylib", "machType" : 6, "b" : "7FFF75FB1000", "vmaddr" : "7FFF56A14000", "buildId" : "893142A5F1533437A22D407EE542B5C5" }, { "path" : "/usr/lib/libSystem.B.dylib", "machType" : 6, "b" : "7FFF73E8E000", "vmaddr" : "7FFF548F1000", "buildId" : "B10069487AD03CA981E0833F4DD6BFB4" }, { "path" : "/System/Library/Frameworks/CoreFoundation.framework/Versions/A/CoreFoundation", "machType" : 6, "b" : "7FFF4AF17000", "vmaddr" : "7FFF2B97A000", "buildId" : "B2850F42CE013156B121FD4777290C8F" }, { "path" : "/System/Library/Frameworks/Security.framework/Versions/A/Security", "machType" : 6, "b" : "7FFF56446000", "vmaddr" : "7FFF36EA9000", "buildId" : "DF7677A797653B6A9D1C3589145E4B65" }, { "path" : "/usr/lib/libc++.1.dylib", "machType" : 6, "b" : "7FFF740D1000", "vmaddr" : "7FFF54B34000", "buildId" : "9A60A1906C34339FBB3DAACE942009A4" }, { "path" : "/usr/lib/libcrypto.42.dylib", "machType" : 6, "b" : "7FFF7478A000", "vmaddr" : "7FFF551ED000", "buildId" : "BD99538830833E74AE7DC4FCA5938E8E" }, { "path" : "/usr/lib/libssl.44.dylib", "machType" : 6, "b" : "7FFF762BD000", "vmaddr" : "7FFF56D20000", "buildId" : "F1DE913C717A30139780DBF79406C58E" }, { "path" : "/System/Library/Frameworks/LDAP.framework/Versions/A/LDAP", "machType" : 6, "b" : "7FFF4F09F000", "vmaddr" : "7FFF2FB02000", "buildId" : "95DAD9EE9B6F3FF5A5EFF6672AD3CC55" }, { "path" : "/System/Library/Frameworks/Kerberos.framework/Versions/A/Kerberos", "machType" : 6, "b" : "7FFF4F085000", "vmaddr" : "7FFF2FAE8000", "buildId" : "DB1E067937E13B93978932F63D660C3B" }, { "path" : "/usr/lib/libapple_nghttp2.dylib", "machType" : 6, "b" : "7FFF73F1E000", "vmaddr" : "7FFF54981000", "buildId" : "6F04250A66863FDC9A8D290C64B06502" }, { "path" : "/usr/lib/libz.1.dylib", "machType" : 6, "b" : "7FFF76534000", "vmaddr" : "7FFF56F97000", "buildId" : "B048FC1F058F3A08A1FE81D5308CB3E6" }, { "path" : "/System/Library/PrivateFrameworks/TrustEvaluationAgent.framework/Versions/A/TrustEvaluationAgent", "machType" : 6, "b" : "7FFF71BC4000", "vmaddr" : "7FFF52627000", "buildId" : "15DF9C7354E43C41BCF4378338C55FB4" }, { "path" : "/usr/lib/system/libcache.dylib", "machType" : 6, "b" : "7FFF76D2A000", "vmaddr" : "7FFF5778D000", "buildId" : "1987D1E1DB113291B12AEBD55848E02D" }, { "path" : "/usr/lib/system/libcommonCrypto.dylib", "machType" : 6, "b" : "7FFF76D2F000", "vmaddr" : "7FFF57792000", "buildId" : "1765BB6E67843653B16BCB839721DC9A" }, { "path" : "/usr/lib/system/libcompiler_rt.dylib", "machType" : 6, "b" : "7FFF76D3A000", "vmaddr" : "7FFF5779D000", "buildId" : "5212BA7BB7EA37B4AF6EAC4F507EDFB8" }, { "path" : "/usr/lib/system/libcopyfile.dylib", "machType" : 6, "b" : "7FFF76D42000", "vmaddr" : "7FFF577A5000", "buildId" : "98CD00CD9B913B5CA9DB842638050FA8" }, { "path" : "/usr/lib/system/libcorecrypto.dylib", "machType" : 6, "b" : "7FFF76D4C000", "vmaddr" : "7FFF577AF000", "buildId" : "01464D24570C3B839D18467769E0FCDD" }, { "path" : "/usr/lib/system/libdispatch.dylib", "machType" : 6, "b" : "7FFF76E57000", "vmaddr" : "7FFF578BA000", "buildId" : "97273678E94C3C8C89F62E2020F4B43B" }, { "path" : "/usr/lib/system/libdyld.dylib", "machType" : 6, "b" : "7FFF76E91000", "vmaddr" : "7FFF578F4000", "buildId" : "002418CCAD113D10865B015591D24E6C" }, { "path" : "/usr/lib/system/libkeymgr.dylib", "machType" : 6, "b" : "7FFF76EBE000", "vmaddr" : "7FFF57921000", "buildId" : "0D0F9CA28D5A3273872359987B5827F2" }, { "path" : "/usr/lib/system/liblaunch.dylib", "machType" : 6, "b" : "7FFF76ECC000", "vmaddr" : "7FFF5792F000", "buildId" : "2B07E27ED4043E989D28BCA641E5C479" }, { "path" : "/usr/lib/system/libmacho.dylib", "machType" : 6, "b" : "7FFF76ECD000", "vmaddr" : "7FFF57930000", "buildId" : "A377D60877AB3F6E90F0B4F251A5C12F" }, { "path" : "/usr/lib/system/libquarantine.dylib", "machType" : 6, "b" : "7FFF76ED3000", "vmaddr" : "7FFF57936000", "buildId" : "6D0BC770734836089254F7FFBD347634" }, { "path" : "/usr/lib/system/libremovefile.dylib", "machType" : 6, "b" : "7FFF76ED6000", "vmaddr" : "7FFF57939000", "buildId" : "9FBEB2FFEEBE31BCBCFCC71F8D0E99B6" }, { "path" : "/usr/lib/system/libsystem_asl.dylib", "machType" : 6, "b" : "7FFF76ED8000", "vmaddr" : "7FFF5793B000", "buildId" : "A62A724938B833FA9875F1852590796C" }, { "path" : "/usr/lib/system/libsystem_blocks.dylib", "machType" : 6, "b" : "7FFF76EF0000", "vmaddr" : "7FFF57953000", "buildId" : "A453E8EE860D3CEDB5DCBE54E9DB4348" }, { "path" : "/usr/lib/system/libsystem_c.dylib", "machType" : 6, "b" : "7FFF76EF1000", "vmaddr" : "7FFF57954000", "buildId" : "7EDACF782FA335B8B051D70475A35117" }, { "path" : "/usr/lib/system/libsystem_configuration.dylib", "machType" : 6, "b" : "7FFF76F79000", "vmaddr" : "7FFF579DC000", "buildId" : "2B4A836D68A433E68D48CD4486B03387" }, { "path" : "/usr/lib/system/libsystem_coreservices.dylib", "machType" : 6, "b" : "7FFF76F7D000", "vmaddr" : "7FFF579E0000", "buildId" : "719F75A474C53BA6A09E0C5A3E5889D7" }, { "path" : "/usr/lib/system/libsystem_darwin.dylib", "machType" : 6, "b" : "7FFF76F81000", "vmaddr" : "7FFF579E4000", "buildId" : "EC9B39A59592357789977DC721D20D8C" }, { "path" : "/usr/lib/system/libsystem_dnssd.dylib", "machType" : 6, "b" : "7FFF76F88000", "vmaddr" : "7FFF579EB000", "buildId" : "E9A5ACCFE35F3909AF0A2A37CD217276" }, { "path" : "/usr/lib/system/libsystem_info.dylib", "machType" : 6, "b" : "7FFF76F8F000", "vmaddr" : "7FFF579F2000", "buildId" : "D09D5AE02FDC3A6D93EC729F931B1457" }, { "path" : "/usr/lib/system/libsystem_m.dylib", "machType" : 6, "b" : "7FFF77004000", "vmaddr" : "7FFF57A67000", "buildId" : "F19B6DB7014F3820831F389CCDA06EF6" }, { "path" : "/usr/lib/system/libsystem_malloc.dylib", "machType" : 6, "b" : "7FFF77050000", "vmaddr" : "7FFF57AB3000", "buildId" : "011F3AD08E6A3A89AE646E5F6840F30A" }, { "path" : "/usr/lib/system/libsystem_networkextension.dylib", "machType" : 6, "b" : "7FFF7707B000", "vmaddr" : "7FFF57ADE000", "buildId" : "FF06F13AAEFE3A27A073910EF78AEA36" }, { "path" : "/usr/lib/system/libsystem_notify.dylib", "machType" : 6, "b" : "7FFF77086000", "vmaddr" : "7FFF57AE9000", "buildId" : "145B5CFCCF7333CEBD3DE8DDE268FFDE" }, { "path" : "/usr/lib/system/libsystem_sandbox.dylib", "machType" : 6, "b" : "7FFF770A3000", "vmaddr" : "7FFF57B06000", "buildId" : "9494594B5199318682AB5FF8BED6EE16" }, { "path" : "/usr/lib/system/libsystem_secinit.dylib", "machType" : 6, "b" : "7FFF770A7000", "vmaddr" : "7FFF57B0A000", "buildId" : "EF1EA47B7B2235E8BD9BF7003DCB96AE" }, { "path" : "/usr/lib/system/libsystem_kernel.dylib", "machType" : 6, "b" : "7FFF76FDB000", "vmaddr" : "7FFF57A3E000", "buildId" : "EA204E3C870B30DDB4AFD1BB66420D14" }, { "path" : "/usr/lib/system/libsystem_platform.dylib", "machType" : 6, "b" : "7FFF7708E000", "vmaddr" : "7FFF57AF1000", "buildId" : "9D1FE5E4EB7D3B3FA8D1A96D9CF1348C" }, { "path" : "/usr/lib/system/libsystem_pthread.dylib", "machType" : 6, "b" : "7FFF77098000", "vmaddr" : "7FFF57AFB000", "buildId" : "2D5C08FF484F3D599132CE1DCB3F76D7" }, { "path" : "/usr/lib/system/libsystem_symptoms.dylib", "machType" : 6, "b" : "7FFF770AA000", "vmaddr" : "7FFF57B0D000", "buildId" : "03F1C2DD0F5A3D9D88F6B26C0F94EB52" }, { "path" : "/usr/lib/system/libsystem_trace.dylib", "machType" : 6, "b" : "7FFF770B2000", "vmaddr" : "7FFF57B15000", "buildId" : "FC761C3B54343A52912DF1B15FAA8EB2" }, { "path" : "/usr/lib/system/libunwind.dylib", "machType" : 6, "b" : "7FFF770C9000", "vmaddr" : "7FFF57B2C000", "buildId" : "24A97A67F0173CFCB0D06BD0224B1336" }, { "path" : "/usr/lib/system/libxpc.dylib", "machType" : 6, "b" : "7FFF770CF000", "vmaddr" : "7FFF57B32000", "buildId" : "7DEE23006D8E3C009C63E3E80D56B0C4" }, { "path" : "/usr/lib/libobjc.A.dylib", "machType" : 6, "b" : "7FFF756C5000", "vmaddr" : "7FFF56128000", "buildId" : "7C31262743CB323493244DEA92D59F50" }, { "path" : "/usr/lib/libc++abi.dylib", "machType" : 6, "b" : "7FFF74125000", "vmaddr" : "7FFF54B88000", "buildId" : "38C09CED9090371990F304A2749F5428" }, { "path" : "/usr/lib/libsasl2.2.dylib", "machType" : 6, "b" : "7FFF76007000", "vmaddr" : "7FFF56A6A000", "buildId" : "1098761467633B5D9F2891D121BB4924" }, { "path" : "/System/Library/PrivateFrameworks/CoreDaemon.framework/Versions/B/CoreDaemon", "machType" : 6, "b" : "7FFF5E4B7000", "vmaddr" : "7FFF3EF1A000", "buildId" : "89BDACE632AA3933BD8CA44650488873" }, { "path" : "/System/Library/Frameworks/SystemConfiguration.framework/Versions/A/SystemConfiguration", "machType" : 6, "b" : "7FFF56BA2000", "vmaddr" : "7FFF37605000", "buildId" : "30C8327F3EFF35209C50016F8B6B954F" }, { "path" : "/System/Library/Frameworks/IOKit.framework/Versions/A/IOKit", "machType" : 6, "b" : "7FFF4D851000", "vmaddr" : "7FFF2E2B4000", "buildId" : "8A90F54786EF3DFB92FE0E2C0376DD84" }, { "path" : "/System/Library/Frameworks/Foundation.framework/Versions/C/Foundation", "machType" : 6, "b" : "7FFF4D199000", "vmaddr" : "7FFF2DBFC000", "buildId" : "A85BF812B78436B989BBE29772B0708C" }, { "path" : "/System/Library/PrivateFrameworks/AppleFSCompression.framework/Versions/A/AppleFSCompression", "machType" : 6, "b" : "7FFF5B05B000", "vmaddr" : "7FFF3BABE000", "buildId" : "3CF60CE8976E3CB8959DDD0948C1C2DE" }, { "path" : "/usr/lib/libDiagnosticMessagesClient.dylib", "machType" : 6, "b" : "7FFF73A4E000", "vmaddr" : "7FFF544B1000", "buildId" : "A14D0819097034CD868080E4D7FE8C2C" }, { "path" : "/usr/lib/libOpenScriptingUtil.dylib", "machType" : 6, "b" : "7FFF73D4E000", "vmaddr" : "7FFF547B1000", "buildId" : "4D603146EDA53A749FF84F75D8BB9BC6" }, { "path" : "/usr/lib/libauto.dylib", "machType" : 6, "b" : "7FFF73FE2000", "vmaddr" : "7FFF54A45000", "buildId" : "3E3780E196F33A2291C592F9A5805518" }, { "path" : "/usr/lib/libbsm.0.dylib", "machType" : 6, "b" : "7FFF740B2000", "vmaddr" : "7FFF54B15000", "buildId" : "CF381E0B025B364FA83D2527E03F1AA3" }, { "path" : "/usr/lib/libcoretls.dylib", "machType" : 6, "b" : "7FFF743DA000", "vmaddr" : "7FFF54E3D000", "buildId" : "4C64BE3E41E330208BB707E90C0C861C" }, { "path" : "/usr/lib/libcoretls_cfhelpers.dylib", "machType" : 6, "b" : "7FFF743F1000", "vmaddr" : "7FFF54E54000", "buildId" : "0959B3E9664335898BB321D52CDF0EF1" }, { "path" : "/usr/lib/libpam.2.dylib", "machType" : 6, "b" : "7FFF75E5C000", "vmaddr" : "7FFF568BF000", "buildId" : "586CF87F349C393DAEEBFB75F94A5EB7" }, { "path" : "/usr/lib/libsqlite3.dylib", "machType" : 6, "b" : "7FFF7601C000", "vmaddr" : "7FFF56A7F000", "buildId" : "6404BA3BBCA4301FB2FE8776105A2AA3" }, { "path" : "/usr/lib/libxar.1.dylib", "machType" : 6, "b" : "7FFF76416000", "vmaddr" : "7FFF56E79000", "buildId" : "39CCF46BC81A34B192A158C4E5DA846E" }, { "path" : "/System/Library/Frameworks/DiskArbitration.framework/Versions/A/DiskArbitration", "machType" : 6, "b" : "7FFF4CFCE000", "vmaddr" : "7FFF2DA31000", "buildId" : "F481F2C0884E32658111ABBEC93F0920" }, { "path" : "/usr/lib/libarchive.2.dylib", "machType" : 6, "b" : "7FFF73F35000", "vmaddr" : "7FFF54998000", "buildId" : "472899468504396691276CE39993DC2C" }, { "path" : "/usr/lib/libicucore.A.dylib", "machType" : 6, "b" : "7FFF74B81000", "vmaddr" : "7FFF555E4000", "buildId" : "A0D6391876E93C1BB25546F4C1DA7FE8" }, { "path" : "/usr/lib/libxml2.2.dylib", "machType" : 6, "b" : "7FFF76428000", "vmaddr" : "7FFF56E8B000", "buildId" : "AA4E1B1F0FDE32749FA575446298D1AC" }, { "path" : "/System/Library/Frameworks/CFNetwork.framework/Versions/A/CFNetwork", "machType" : 6, "b" : "7FFF49DEA000", "vmaddr" : "7FFF2A84D000", "buildId" : "B2133D0D13993F1780F0313E3A241C89" }, { "path" : "/System/Library/Frameworks/CoreServices.framework/Versions/A/CoreServices", "machType" : 6, "b" : "7FFF4C16C000", "vmaddr" : "7FFF2CBCF000", "buildId" : "6EC9F377EBD8335892D16586F6F1E8E9" }, { "path" : "/usr/lib/liblangid.dylib", "machType" : 6, "b" : "7FFF74E2F000", "vmaddr" : "7FFF55892000", "buildId" : "22D05C4F769B3075ABCF44A0EBACE028" }, { "path" : "/usr/lib/libCRFSuite.dylib", "machType" : 6, "b" : "7FFF7397F000", "vmaddr" : "7FFF543E2000", "buildId" : "406DAC060C773F90878B4D38F11F0256" }, { "path" : "/usr/lib/libenergytrace.dylib", "machType" : 6, "b" : "7FFF74A28000", "vmaddr" : "7FFF5548B000", "buildId" : "80BB567AFD183497BF97353F57D98CDD" }, { "path" : "/usr/lib/system/libkxld.dylib", "machType" : 6, "b" : "7FFF76EBF000", "vmaddr" : "7FFF57922000", "buildId" : "FBF128C8D3F036B6983AA63B8A3E0E52" }, { "path" : "/usr/lib/libbz2.1.0.dylib", "machType" : 6, "b" : "7FFF740C3000", "vmaddr" : "7FFF54B26000", "buildId" : "272953A18D36329BBDDBE887B347710F" }, { "path" : "/usr/lib/liblzma.5.dylib", "machType" : 6, "b" : "7FFF74E31000", "vmaddr" : "7FFF55894000", "buildId" : "E1F4FD601CE437B9AD9529D348AF1AC0" }, { "path" : "/usr/lib/libnetwork.dylib", "machType" : 6, "b" : "7FFF752E2000", "vmaddr" : "7FFF55D45000", "buildId" : "72C7E9E3B2BE3300BE1B64606222022C" }, { "path" : "/usr/lib/libpcap.A.dylib", "machType" : 6, "b" : "7FFF75E63000", "vmaddr" : "7FFF568C6000", "buildId" : "C08936417DFF3A33BDAE190FF54837E8" }, { "path" : "/System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/FSEvents.framework/Versions/A/FSEvents", "machType" : 6, "b" : "7FFF4C50B000", "vmaddr" : "7FFF2CF6E000", "buildId" : "8406D3798D333611861B7ABD26DB50D2" }, { "path" : "/System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/CarbonCore.framework/Versions/A/CarbonCore", "machType" : 6, "b" : "7FFF4C1EA000", "vmaddr" : "7FFF2CC4D000", "buildId" : "CB87F0C72CD639838E32B6A2EC925352" }, { "path" : "/System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/Metadata.framework/Versions/A/Metadata", "machType" : 6, "b" : "7FFF4C6C6000", "vmaddr" : "7FFF2D129000", "buildId" : "BFFAED002560318ABB8F4E7E5123EC61" }, { "path" : "/System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/OSServices.framework/Versions/A/OSServices", "machType" : 6, "b" : "7FFF4C765000", "vmaddr" : "7FFF2D1C8000", "buildId" : "20C4EEF8D5AC39A09B4A78F88E3EFBCC" }, { "path" : "/System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/SearchKit.framework/Versions/A/SearchKit", "machType" : 6, "b" : "7FFF4C7B0000", "vmaddr" : "7FFF2D213000", "buildId" : "DA08AA6FA6F136C087F4E26294E51A3A" }, { "path" : "/System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/AE.framework/Versions/A/AE", "machType" : 6, "b" : "7FFF4C16D000", "vmaddr" : "7FFF2CBD0000", "buildId" : "55AE7C9E27C330E9A0473B92A6FD53B4" }, { "path" : "/System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/LaunchServices.framework/Versions/A/LaunchServices", "machType" : 6, "b" : "7FFF4C514000", "vmaddr" : "7FFF2CF77000", "buildId" : "A0C91634941038E8BC117A5A369E6BA5" }, { "path" : "/System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/DictionaryServices.framework/Versions/A/DictionaryServices", "machType" : 6, "b" : "7FFF4C4C2000", "vmaddr" : "7FFF2CF25000", "buildId" : "746EB200DC5130AE9CBC608A7B4CC8DA" }, { "path" : "/System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/SharedFileList.framework/Versions/A/SharedFileList", "machType" : 6, "b" : "7FFF4C818000", "vmaddr" : "7FFF2D27B000", "buildId" : "487A8464729E305AB5D1E3FE8EB9CFC5" }, { "path" : "/System/Library/Frameworks/NetFS.framework/Versions/A/NetFS", "machType" : 6, "b" : "7FFF50B82000", "vmaddr" : "7FFF315E5000", "buildId" : "E917806F06073292B2D6A15404D61B99" }, { "path" : "/System/Library/PrivateFrameworks/NetAuth.framework/Versions/A/NetAuth", "machType" : 6, "b" : "7FFF69CFF000", "vmaddr" : "7FFF4A762000", "buildId" : "0D01BBE50269310DB148D19DAE143DEB" }, { "path" : "/System/Library/PrivateFrameworks/login.framework/Versions/A/Frameworks/loginsupport.framework/Versions/A/loginsupport", "machType" : 6, "b" : "7FFF736B3000", "vmaddr" : "7FFF54116000", "buildId" : "3F8D6334BCD636C1BA20CC8503A84375" }, { "path" : "/System/Library/PrivateFrameworks/TCC.framework/Versions/A/TCC", "machType" : 6, "b" : "7FFF717D4000", "vmaddr" : "7FFF52237000", "buildId" : "73CF6FA944CE30C9887F235940976585" }, { "path" : "/System/Library/PrivateFrameworks/CoreNLP.framework/Versions/A/CoreNLP", "machType" : 6, "b" : "7FFF5EC75000", "vmaddr" : "7FFF3F6D8000", "buildId" : "2787782017D03B0285574014E876CCC7" }, { "path" : "/System/Library/PrivateFrameworks/MetadataUtilities.framework/Versions/A/MetadataUtilities", "machType" : 6, "b" : "7FFF69794000", "vmaddr" : "7FFF4A1F7000", "buildId" : "38BB1FB73336384CB71F4D0D402EB606" }, { "path" : "/usr/lib/libmecabra.dylib", "machType" : 6, "b" : "7FFF74F06000", "vmaddr" : "7FFF55969000", "buildId" : "D71F71E030E23DB3B6367DE13D51FB4B" }, { "path" : "/System/Library/Frameworks/ApplicationServices.framework/Versions/A/ApplicationServices", "machType" : 6, "b" : "7FFF49335000", "vmaddr" : "7FFF29D98000", "buildId" : "84097DEBE2FC39018DD7A670EA2274E0" }, { "path" : "/System/Library/Frameworks/CoreGraphics.framework/Versions/A/CoreGraphics", "machType" : 6, "b" : "7FFF4B35D000", "vmaddr" : "7FFF2BDC0000", "buildId" : "BC95B558EF773A57A0BC11606C778991" }, { "path" : "/System/Library/Frameworks/CoreText.framework/Versions/A/CoreText", "machType" : 6, "b" : "7FFF4CB44000", "vmaddr" : "7FFF2D5A7000", "buildId" : "59919B0CCBD538778D6FD6048F1E5F42" }, { "path" : "/System/Library/Frameworks/ImageIO.framework/Versions/A/ImageIO", "machType" : 6, "b" : "7FFF4D945000", "vmaddr" : "7FFF2E3A8000", "buildId" : "75E46A31D87D35CE86A496A50971FDB2" }, { "path" : "/System/Library/Frameworks/ColorSync.framework/Versions/A/ColorSync", "machType" : 6, "b" : "7FFF4A6B0000", "vmaddr" : "7FFF2B113000", "buildId" : "31648BB672393D0E81B1BCF51FEF557F" }, { "path" : "/System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/ATS.framework/Versions/A/ATS", "machType" : 6, "b" : "7FFF49336000", "vmaddr" : "7FFF29D99000", "buildId" : "A258DA73114B3102A0564AAAD3CEB9DD" }, { "path" : "/System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/ColorSyncLegacy.framework/Versions/A/ColorSyncLegacy", "machType" : 6, "b" : "7FFF49685000", "vmaddr" : "7FFF2A0E8000", "buildId" : "C0D9E23CABA039DEA4EB5A41C5499056" }, { "path" : "/System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/HIServices.framework/Versions/A/HIServices", "machType" : 6, "b" : "7FFF49724000", "vmaddr" : "7FFF2A187000", "buildId" : "2BE461FF80B930D3A574AED5724B1C1B" }, { "path" : "/System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/LangAnalysis.framework/Versions/A/LangAnalysis", "machType" : 6, "b" : "7FFF49777000", "vmaddr" : "7FFF2A1DA000", "buildId" : "F5617A2AFEA63832B5BAC2111B98786F" }, { "path" : "/System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/PrintCore.framework/Versions/A/PrintCore", "machType" : 6, "b" : "7FFF49787000", "vmaddr" : "7FFF2A1EA000", "buildId" : "57C2FE320E743079B626C2D52F2D2717" }, { "path" : "/System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/QD.framework/Versions/A/QD", "machType" : 6, "b" : "7FFF497D1000", "vmaddr" : "7FFF2A234000", "buildId" : "28C7D39F59C93314BECC67045487229C" }, { "path" : "/System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/SpeechSynthesis.framework/Versions/A/SpeechSynthesis", "machType" : 6, "b" : "7FFF4980B000", "vmaddr" : "7FFF2A26E000", "buildId" : "5E7B9BD4122B3012A0443259C97E7509" }, { "path" : "/System/Library/PrivateFrameworks/SkyLight.framework/Versions/A/SkyLight", "machType" : 6, "b" : "7FFF700B2000", "vmaddr" : "7FFF50B15000", "buildId" : "90EB1C2EB2643EC4AF7FCDE7E7585746" }, { "path" : "/System/Library/Frameworks/IOSurface.framework/Versions/A/IOSurface", "machType" : 6, "b" : "7FFF4D8E2000", "vmaddr" : "7FFF2E345000", "buildId" : "85F85EBBEA593A8BB3EB7C20F3CC77AE" }, { "path" : "/System/Library/Frameworks/Accelerate.framework/Versions/A/Accelerate", "machType" : 6, "b" : "7FFF472FA000", "vmaddr" : "7FFF27D5D000", "buildId" : "762942CBCFC93A0C9645A56523A06426" }, { "path" : "/usr/lib/libcompression.dylib", "machType" : 6, "b" : "7FFF7414D000", "vmaddr" : "7FFF54BB0000", "buildId" : "7F4BB18C1FB438258D8B6E6B168774C6" }, { "path" : "/System/Library/Frameworks/CoreDisplay.framework/Versions/A/CoreDisplay", "machType" : 6, "b" : "7FFF4AE26000", "vmaddr" : "7FFF2B889000", "buildId" : "0EB2A997FCAD3D17B1409829961E5327" }, { "path" : "/System/Library/Frameworks/Metal.framework/Versions/A/Metal", "machType" : 6, "b" : "7FFF4FABA000", "vmaddr" : "7FFF3051D000", "buildId" : "FFF7DFF37C4E32C6A0B5C356079D3B7C" }, { "path" : "/System/Library/Frameworks/MetalPerformanceShaders.framework/Versions/A/MetalPerformanceShaders", "machType" : 6, "b" : "7FFF4FD8A000", "vmaddr" : "7FFF307ED000", "buildId" : "69F14BCFC5C53BF89C318F87D2D6130A" }, { "path" : "/System/Library/PrivateFrameworks/MultitouchSupport.framework/Versions/A/MultitouchSupport", "machType" : 6, "b" : "7FFF69A99000", "vmaddr" : "7FFF4A4FC000", "buildId" : "42A23EC964A731C7BF33DF4412ED8A3F" }, { "path" : "/System/Library/Frameworks/QuartzCore.framework/Versions/A/QuartzCore", "machType" : 6, "b" : "7FFF559B9000", "vmaddr" : "7FFF3641C000", "buildId" : "33E846BE179431869BF26ADF62C782A3" }, { "path" : "/System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vImage.framework/Versions/A/vImage", "machType" : 6, "b" : "7FFF47312000", "vmaddr" : "7FFF27D75000", "buildId" : "53FA3611894E3158A654FBD2F70998FE" }, { "path" : "/System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/vecLib", "machType" : 6, "b" : "7FFF4838C000", "vmaddr" : "7FFF28DEF000", "buildId" : "74288115EF6130B6843F0593B31D4929" }, { "path" : "/System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libvMisc.dylib", "machType" : 6, "b" : "7FFF482D8000", "vmaddr" : "7FFF28D3B000", "buildId" : "D5BA4812BFFC3CD0B382905CD8555DA6" }, { "path" : "/System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libvDSP.dylib", "machType" : 6, "b" : "7FFF480F0000", "vmaddr" : "7FFF28B53000", "buildId" : "7B110627A9C13FB7A0770C7741BA25D8" }, { "path" : "/System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib", "machType" : 6, "b" : "7FFF479AC000", "vmaddr" : "7FFF2840F000", "buildId" : "417CA0FCB6CB3FB3ACBC8914E3F62D20" }, { "path" : "/System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libLAPACK.dylib", "machType" : 6, "b" : "7FFF47C99000", "vmaddr" : "7FFF286FC000", "buildId" : "92175DF4863A3780909AA3E5C410F2E9" }, { "path" : "/System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libLinearAlgebra.dylib", "machType" : 6, "b" : "7FFF48043000", "vmaddr" : "7FFF28AA6000", "buildId" : "CB671EE6DEA1391C9B2BAA09A46B4D7A" }, { "path" : "/System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libSparseBLAS.dylib", "machType" : 6, "b" : "7FFF480DC000", "vmaddr" : "7FFF28B3F000", "buildId" : "E9243341DB7737C197C53DFA00DD70FA" }, { "path" : "/System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libQuadrature.dylib", "machType" : 6, "b" : "7FFF48059000", "vmaddr" : "7FFF28ABC000", "buildId" : "1BAE7E222862379FB334A3756067730F" }, { "path" : "/System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBNNS.dylib", "machType" : 6, "b" : "7FFF47C26000", "vmaddr" : "7FFF28689000", "buildId" : "538D12A29B9D3E229896F90F6E69C06E" }, { "path" : "/System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libSparse.dylib", "machType" : 6, "b" : "7FFF4805F000", "vmaddr" : "7FFF28AC2000", "buildId" : "E78B33D3672A3C53B512D3DDB2E9AC8D" }, { "path" : "/System/Library/PrivateFrameworks/GPUWrangler.framework/Versions/A/GPUWrangler", "machType" : 6, "b" : "7FFF65FC3000", "vmaddr" : "7FFF46A26000", "buildId" : "6C820ED9F3063978B5B8432AD97BBDAF" }, { "path" : "/System/Library/PrivateFrameworks/IOAccelerator.framework/Versions/A/IOAccelerator", "machType" : 6, "b" : "7FFF682C3000", "vmaddr" : "7FFF48D26000", "buildId" : "11A50171C8AE3BBC9FB92A3313FFBD31" }, { "path" : "/System/Library/PrivateFrameworks/IOPresentment.framework/Versions/A/IOPresentment", "machType" : 6, "b" : "7FFF682CE000", "vmaddr" : "7FFF48D31000", "buildId" : "6DFD9A6EBF953A2789E7ACAA9E30D90A" }, { "path" : "/System/Library/PrivateFrameworks/DSExternalDisplay.framework/Versions/A/DSExternalDisplay", "machType" : 6, "b" : "7FFF5FA4D000", "vmaddr" : "7FFF404B0000", "buildId" : "787B9748B1203453B8FE61D9E363A9E0" }, { "path" : "/System/Library/Frameworks/OpenGL.framework/Versions/A/Libraries/libCoreFSCache.dylib", "machType" : 6, "b" : "7FFF53FFE000", "vmaddr" : "7FFF34A61000", "buildId" : "222C2A4F7E3230F684592FAB98073A3D" }, { "path" : "/System/Library/Frameworks/MetalPerformanceShaders.framework/Frameworks/MPSCore.framework/Versions/A/MPSCore", "machType" : 6, "b" : "7FFF4FB7E000", "vmaddr" : "7FFF305E1000", "buildId" : "44CE8362E9723697AD6F15BC863BAEB8" }, { "path" : "/System/Library/Frameworks/MetalPerformanceShaders.framework/Frameworks/MPSImage.framework/Versions/A/MPSImage", "machType" : 6, "b" : "7FFF4FB9E000", "vmaddr" : "7FFF30601000", "buildId" : "EE8440DA66DF3923ABBCE0543211C069" }, { "path" : "/System/Library/Frameworks/MetalPerformanceShaders.framework/Frameworks/MPSNeuralNetwork.framework/Versions/A/MPSNeuralNetwork", "machType" : 6, "b" : "7FFF4FC43000", "vmaddr" : "7FFF306A6000", "buildId" : "F2CF26B673F136448FE9CDB9B2C4501F" }, { "path" : "/System/Library/Frameworks/MetalPerformanceShaders.framework/Frameworks/MPSMatrix.framework/Versions/A/MPSMatrix", "machType" : 6, "b" : "7FFF4FC1B000", "vmaddr" : "7FFF3067E000", "buildId" : "E64450DF2B96331EB7F4666E00571C70" }, { "path" : "/System/Library/Frameworks/MetalPerformanceShaders.framework/Frameworks/MPSRayIntersector.framework/Versions/A/MPSRayIntersector", "machType" : 6, "b" : "7FFF4FD6F000", "vmaddr" : "7FFF307D2000", "buildId" : "B33A35C30393366BACFBF4BB6A5F7B4A" }, { "path" : "/System/Library/PrivateFrameworks/MetalTools.framework/Versions/A/MetalTools", "machType" : 6, "b" : "7FFF697BD000", "vmaddr" : "7FFF4A220000", "buildId" : "CBE2176A80483A9CAFE413973D44C704" }, { "path" : "/System/Library/PrivateFrameworks/AggregateDictionary.framework/Versions/A/AggregateDictionary", "machType" : 6, "b" : "7FFF5A905000", "vmaddr" : "7FFF3B368000", "buildId" : "A6AF8AC41F2537C49157A02E9C200926" }, { "path" : "/usr/lib/libMobileGestalt.dylib", "machType" : 6, "b" : "7FFF73D2E000", "vmaddr" : "7FFF54791000", "buildId" : "99A06C8A97D6383D862CF453BABB48A4" }, { "path" : "/System/Library/Frameworks/CoreImage.framework/Versions/A/CoreImage", "machType" : 6, "b" : "7FFF4B9EE000", "vmaddr" : "7FFF2C451000", "buildId" : "11026E39D2FF3CF68ACE7BA293F9853E" }, { "path" : "/System/Library/Frameworks/CoreVideo.framework/Versions/A/CoreVideo", "machType" : 6, "b" : "7FFF4CCA7000", "vmaddr" : "7FFF2D70A000", "buildId" : "10CF8E5207E3382B80912CEEEFFA69B4" }, { "path" : "/System/Library/Frameworks/OpenGL.framework/Versions/A/OpenGL", "machType" : 6, "b" : "7FFF54BA7000", "vmaddr" : "7FFF3560A000", "buildId" : "94B5CF345BD636529A8CE9C56E0A9FB4" }, { "path" : "/System/Library/PrivateFrameworks/GraphVisualizer.framework/Versions/A/GraphVisualizer", "machType" : 6, "b" : "7FFF66DD4000", "vmaddr" : "7FFF47837000", "buildId" : "48D020B759383FAEB468E291AEE2C06F" }, { "path" : "/System/Library/PrivateFrameworks/FaceCore.framework/Versions/A/FaceCore", "machType" : 6, "b" : "7FFF60C53000", "vmaddr" : "7FFF416B6000", "buildId" : "A576E2DABF6F3B188FEB324E5C5FA9BD" }, { "path" : "/System/Library/Frameworks/OpenCL.framework/Versions/A/OpenCL", "machType" : 6, "b" : "7FFF5362C000", "vmaddr" : "7FFF3408F000", "buildId" : "056BAD8A23BC3F749E2C3AC81E7DEA5A" }, { "path" : "/usr/lib/libFosl_dynamic.dylib", "machType" : 6, "b" : "7FFF73A86000", "vmaddr" : "7FFF544E9000", "buildId" : "1B5DD4E28AE0315E829ED5BFCD264EA8" }, { "path" : "/System/Library/PrivateFrameworks/OTSVG.framework/Versions/A/OTSVG", "machType" : 6, "b" : "7FFF6A56A000", "vmaddr" : "7FFF4AFCD000", "buildId" : "5BF1A9EB269432679514A4EB3BEF4081" }, { "path" : "/System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/ATS.framework/Versions/A/Resources/libFontParser.dylib", "machType" : 6, "b" : "7FFF4943A000", "vmaddr" : "7FFF29E9D000", "buildId" : "3602D55B3B9E3B3AA81408C1244A8AE4" }, { "path" : "/System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/ATS.framework/Versions/A/Resources/libFontRegistry.dylib", "machType" : 6, "b" : "7FFF49552000", "vmaddr" : "7FFF29FB5000", "buildId" : "2A56347B28093407A8B42AB88E484062" }, { "path" : "/System/Library/Frameworks/ImageIO.framework/Versions/A/Resources/libJPEG.dylib", "machType" : 6, "b" : "7FFF4DBB3000", "vmaddr" : "7FFF2E616000", "buildId" : "171A8AC4AADA376F9F2CB9C978DB1007" }, { "path" : "/System/Library/Frameworks/ImageIO.framework/Versions/A/Resources/libTIFF.dylib", "machType" : 6, "b" : "7FFF4DEC5000", "vmaddr" : "7FFF2E928000", "buildId" : "F59557C9C7613E6F85D10FBFFD53ED5C" }, { "path" : "/System/Library/Frameworks/ImageIO.framework/Versions/A/Resources/libPng.dylib", "machType" : 6, "b" : "7FFF4DE9B000", "vmaddr" : "7FFF2E8FE000", "buildId" : "FBCEE909F5733AD6A45FAF32612BF8A2" }, { "path" : "/System/Library/Frameworks/ImageIO.framework/Versions/A/Resources/libGIF.dylib", "machType" : 6, "b" : "7FFF4DAD1000", "vmaddr" : "7FFF2E534000", "buildId" : "4774EBDF583B3DDDA0E19F427CB6A074" }, { "path" : "/System/Library/Frameworks/ImageIO.framework/Versions/A/Resources/libJP2.dylib", "machType" : 6, "b" : "7FFF4DAD6000", "vmaddr" : "7FFF2E539000", "buildId" : "697BB77FA682339F865935432962432D" }, { "path" : "/System/Library/Frameworks/ImageIO.framework/Versions/A/Resources/libRadiance.dylib", "machType" : 6, "b" : "7FFF4DEC2000", "vmaddr" : "7FFF2E925000", "buildId" : "56907025D5CE3A9EACCBA376C2599853" }, { "path" : "/System/Library/PrivateFrameworks/AppleJPEG.framework/Versions/A/AppleJPEG", "machType" : 6, "b" : "7FFF5B1B2000", "vmaddr" : "7FFF3BC15000", "buildId" : "4C1F426B7D77398096337DBD8C666B9A" }, { "path" : "/System/Library/Frameworks/OpenGL.framework/Versions/A/Libraries/libGFXShared.dylib", "machType" : 6, "b" : "7FFF54009000", "vmaddr" : "7FFF34A6C000", "buildId" : "8C50BF27B5253B23B86CF444ADF97851" }, { "path" : "/System/Library/Frameworks/OpenGL.framework/Versions/A/Libraries/libGLU.dylib", "machType" : 6, "b" : "7FFF541CC000", "vmaddr" : "7FFF34C2F000", "buildId" : "CB3B0579D9A23CA589420C8344FAD054" }, { "path" : "/System/Library/Frameworks/OpenGL.framework/Versions/A/Libraries/libGL.dylib", "machType" : 6, "b" : "7FFF54012000", "vmaddr" : "7FFF34A75000", "buildId" : "2AC457EA1BD33C8EAFAB7EA6234EB749" }, { "path" : "/System/Library/Frameworks/OpenGL.framework/Versions/A/Libraries/libGLImage.dylib", "machType" : 6, "b" : "7FFF5401E000", "vmaddr" : "7FFF34A81000", "buildId" : "AA027AFAC115386189B20AE946838952" }, { "path" : "/System/Library/Frameworks/OpenGL.framework/Versions/A/Libraries/libCVMSPluginSupport.dylib", "machType" : 6, "b" : "7FFF53FFB000", "vmaddr" : "7FFF34A5E000", "buildId" : "8E051EA755B63DF1982172C391DE953B" }, { "path" : "/System/Library/Frameworks/OpenGL.framework/Versions/A/Libraries/libCoreVMClient.dylib", "machType" : 6, "b" : "7FFF54004000", "vmaddr" : "7FFF34A67000", "buildId" : "6789ECD491DD32EFA1FDF27D2344CD8B" }, { "path" : "/usr/lib/libcups.2.dylib", "machType" : 6, "b" : "7FFF7489E000", "vmaddr" : "7FFF55301000", "buildId" : "095619DC923339379E505F10D917A40D" }, { "path" : "/System/Library/Frameworks/GSS.framework/Versions/A/GSS", "machType" : 6, "b" : "7FFF4D5B5000", "vmaddr" : "7FFF2E018000", "buildId" : "E2B90D08385731559FCC07D778988EC9" }, { "path" : "/usr/lib/libiconv.2.dylib", "machType" : 6, "b" : "7FFF74A90000", "vmaddr" : "7FFF554F3000", "buildId" : "2047C9B73F743A95810D2ED8F0475A99" }, { "path" : "/System/Library/PrivateFrameworks/Heimdal.framework/Versions/A/Heimdal", "machType" : 6, "b" : "7FFF66F49000", "vmaddr" : "7FFF479AC000", "buildId" : "D97FCF19EAD63E2FBE88F817E45CAE96" }, { "path" : "/usr/lib/libheimdal-asn1.dylib", "machType" : 6, "b" : "7FFF74A60000", "vmaddr" : "7FFF554C3000", "buildId" : "73F60D6F76F835EF9C869A81225EE4BE" }, { "path" : "/System/Library/Frameworks/OpenDirectory.framework/Versions/A/OpenDirectory", "machType" : 6, "b" : "7FFF536A0000", "vmaddr" : "7FFF34103000", "buildId" : "A8020CEE5B783581A735EA2833683F31" }, { "path" : "/System/Library/PrivateFrameworks/CommonAuth.framework/Versions/A/CommonAuth", "machType" : 6, "b" : "7FFF5D9D8000", "vmaddr" : "7FFF3E43B000", "buildId" : "93335CB6ABEB3EC7A0408A667F40D5F3" }, { "path" : "/System/Library/Frameworks/OpenDirectory.framework/Versions/A/Frameworks/CFOpenDirectory.framework/Versions/A/CFOpenDirectory", "machType" : 6, "b" : "7FFF53684000", "vmaddr" : "7FFF340E7000", "buildId" : "F03D84EB49B23A009127B9A269824026" }, { "path" : "/System/Library/Frameworks/SecurityFoundation.framework/Versions/A/SecurityFoundation", "machType" : 6, "b" : "7FFF56747000", "vmaddr" : "7FFF371AA000", "buildId" : "1EE899E6222A3526B505B0D0B6FA042A" }, { "path" : "/System/Library/PrivateFrameworks/APFS.framework/Versions/A/APFS", "machType" : 6, "b" : "7FFF59E4B000", "vmaddr" : "7FFF3A8AE000", "buildId" : "2D22485D552D3CB69FE138547597918F" }, { "path" : "/usr/lib/libutil.dylib", "machType" : 6, "b" : "7FFF76412000", "vmaddr" : "7FFF56E75000", "buildId" : "CE9B18C966ED32D49D2901F8FCB467B0" }, { "path" : "/usr/lib/libcharset.1.dylib", "machType" : 6, "b" : "7FFF7413B000", "vmaddr" : "7FFF54B9E000", "buildId" : "2A27E064314C359C93FC8A9B06206174" }, { "path" : "/System/Library/Frameworks/CoreAudio.framework/Versions/A/CoreAudio", "machType" : 6, "b" : "7FFF4A98B000", "vmaddr" : "7FFF2B3EE000", "buildId" : "1E8E64E60E58375A97F707CB4EE181AC" }, { "path" : "/System/Library/Frameworks/AudioToolbox.framework/Versions/A/AudioToolbox", "machType" : 6, "b" : "7FFF49818000", "vmaddr" : "7FFF2A27B000", "buildId" : "04F482F1E1C139558A6C8AA152AA06F3" }, { "path" : "/System/Library/PrivateFrameworks/AppleSauce.framework/Versions/A/AppleSauce", "machType" : 6, "b" : "7FFF5B44F000", "vmaddr" : "7FFF3BEB2000", "buildId" : "F49107C73C5130248EF1C57643BE4F3B" }, { "path" : "/System/Library/PrivateFrameworks/AssertionServices.framework/Versions/A/AssertionServices", "machType" : 6, "b" : "7FFF5B5D0000", "vmaddr" : "7FFF3C033000", "buildId" : "456E507A456136289FBE173ACE7429D8" }, { "path" : "/System/Library/PrivateFrameworks/BaseBoard.framework/Versions/A/BaseBoard", "machType" : 6, "b" : "7FFF5BD00000", "vmaddr" : "7FFF3C763000", "buildId" : "68FA8044F3CD3BC69DAB27DACF52BFC0" }, { "path" : "/usr/lib/libmecab.1.0.0.dylib", "machType" : 6, "b" : "7FFF74E61000", "vmaddr" : "7FFF558C4000", "buildId" : "A8D0379B85FA3B3D89ED5CF2C3826AB2" }, { "path" : "/usr/lib/libgermantok.dylib", "machType" : 6, "b" : "7FFF74A5A000", "vmaddr" : "7FFF554BD000", "buildId" : "E5F0F794FF273D64AE52C78C6A84DD67" }, { "path" : "/usr/lib/libThaiTokenizer.dylib", "machType" : 6, "b" : "7FFF73F0B000", "vmaddr" : "7FFF5496E000", "buildId" : "ADB37DC37D9B3E73A72ABCC3433C937A" }, { "path" : "/usr/lib/libChineseTokenizer.dylib", "machType" : 6, "b" : "7FFF739B6000", "vmaddr" : "7FFF54419000", "buildId" : "9B7F61093A5D36419A7E31D2239D73EE" }, { "path" : "/System/Library/PrivateFrameworks/LanguageModeling.framework/Versions/A/LanguageModeling", "machType" : 6, "b" : "7FFF6897B000", "vmaddr" : "7FFF493DE000", "buildId" : "3DE3CE61542B37B7883E4B9717CAC65F" }, { "path" : "/System/Library/PrivateFrameworks/CoreEmoji.framework/Versions/A/CoreEmoji", "machType" : 6, "b" : "7FFF5E6BA000", "vmaddr" : "7FFF3F11D000", "buildId" : "228457B3E191356E9A5B3C0438D05FBA" }, { "path" : "/System/Library/PrivateFrameworks/Lexicon.framework/Versions/A/Lexicon", "machType" : 6, "b" : "7FFF68A57000", "vmaddr" : "7FFF494BA000", "buildId" : "4B5E843E28093E7095609254E2656419" }, { "path" : "/System/Library/PrivateFrameworks/LinguisticData.framework/Versions/A/LinguisticData", "machType" : 6, "b" : "7FFF68A9A000", "vmaddr" : "7FFF494FD000", "buildId" : "F529B961098C3E4CA3E99DA9BFA1B3F0" }, { "path" : "/usr/lib/libcmph.dylib", "machType" : 6, "b" : "7FFF7413C000", "vmaddr" : "7FFF54B9F000", "buildId" : "9C52B2FE179F32ACB87E2AFC49ABF817" }, { "path" : "/System/Library/Frameworks/CoreData.framework/Versions/A/CoreData", "machType" : 6, "b" : "7FFF4AAA0000", "vmaddr" : "7FFF2B503000", "buildId" : "132CB39B8D5830FAB8AD49BFFF34B293" }, { "path" : "/System/Library/Frameworks/ServiceManagement.framework/Versions/A/ServiceManagement", "machType" : 6, "b" : "7FFF56805000", "vmaddr" : "7FFF37268000", "buildId" : "FCF7BABADDDD37708DAC7069850203C2" }, { "path" : "/System/Library/PrivateFrameworks/BackgroundTaskManagement.framework/Versions/A/BackgroundTaskManagement", "machType" : 6, "b" : "7FFF5BC61000", "vmaddr" : "7FFF3C6C4000", "buildId" : "2A396FC07B7930889A82FB93C1181A57" }, { "path" : "/usr/lib/libxslt.1.dylib", "machType" : 6, "b" : "7FFF7650B000", "vmaddr" : "7FFF56F6E000", "buildId" : "E330D3A2E32B378A973EA8D245C0F712" }, { "path" : "/System/Library/PrivateFrameworks/AppleSRP.framework/Versions/A/AppleSRP", "machType" : 6, "b" : "7FFF5B44A000", "vmaddr" : "7FFF3BEAD000", "buildId" : "EDD16B2E4F353E13B389CF77B3CAD4EB" } ] }}
 mongod(_ZN5mongo15printStackTraceERNSt3__113basic_ostreamIcNS0_11char_traitsIcEEEE+0x39) [0x1055de359]
 mongod(_ZN5mongo12_GLOBAL__N_110abruptQuitEi+0xBD) [0x1055ddc1d]
 libsystem_platform.dylib(_sigtramp+0x1D) [0x7fff77092b5d]
 ??? [0x0]
 libsystem_c.dylib(abort+0x7F) [0x7fff76f4c6a6]
 mongod(_ZN5mongo25fassertFailedWithLocationEiPKcj+0x24B) [0x1055d436b]
 mongod(_ZN5mongo12_GLOBAL__N_141mdb_handle_error_with_startup_suppressionEP18__wt_event_handlerP12__wt_sessioniPKc+0x235) [0x103e19905]
 mongod(__eventv+0x595) [0x103f24905]
 mongod(__wt_err_func+0x84) [0x103f2434c]
 mongod(__wt_panic+0x48) [0x103f2528e]
 mongod(__log_server+0x61D) [0x103e7fbbd]
 libsystem_pthread.dylib(_pthread_body+0x7E) [0x7fff7709b2eb]
 libsystem_pthread.dylib(_pthread_start+0x42) [0x7fff7709e249]
 libsystem_pthread.dylib(thread_start+0xD) [0x7fff7709a40d]
-----  END BACKTRACE  -----
